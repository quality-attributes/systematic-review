doc_id,Authors,DOI,Title,Abstract,Keywords,Conference / Journal,Achronym
1,"Jindal, R. Malhotra, R. Jain, A.",10.1109/ICACCI.2016.7732349,Automated classification of security requirements,"Requirement engineers are not able to elicit and analyze the security requirements clearly, that are essential for the development of secure and reliable software. Proper identification of security requirements present in the Software Requirement Specification (SRS) document has been a problem being faced by the developers. As a result, they are not able to deliver the software free from threats and vulnerabilities. Thus, in this paper, we intend to mine the descriptions of security requirements present in the SRS document and thereafter develop the classification models. The security-based descriptions are analyzed using text mining techniques and are then classified into four types of security requirements viz. authentication-authorization, access control, cryptography-encryption and data integrity using J48 decision tree method. Corresponding to each type of security requirement, a prediction model has been developed. The effectiveness of the prediction models is evaluated against requirement specifications collected from 15 projects which have been developed by MS students at DePaul University. The result analysis indicated that all the four models have performed very well in predicting their respective type of security requirements.","﻿Non-functional requirements, Text mining, Machine learning, Security requirements, Requirement engineering, Requirement elicitation, Receiver Operating Characteristics","International Conference on Advances in Computing, Communications and Informatics",ICACCI
2,"Wang, C. Zhang, F. Liang, P. Daneva, M. van Sinderen, M.",10.1145/3239235.3267428,Can app changelogs improve requirements classification from app reviews?: an exploratory study,"[Background] Recent research on mining app reviews for software evolution indicated that the elicitation and analysis of user requirements can benefit from supplementing user reviews by data from other sources. However, only a few studies reported results of leveraging app changelogs together with app reviews. [Aims] Motivated by those findings, this exploratory experimental study looks into the role of app changelogs in the classification of requirements derived from app reviews. We aim at understanding if the use of app changelogs can lead to more accurate identification and classification of functional and non-functional requirements from app reviews. We also want to know which classification technique works better in this context. [Method] We did a case study on the effect of app changelogs on automatic classification of app reviews. Specifically, manual labeling, text preprocessing, and four supervised machine learning algorithms were applied to a series of experiments, varying in the number of app changelogs in the experimental data. [Results] We compared the accuracy of requirements classification from app reviews, by training the four classifiers with varying combinations of app reviews and changelogs. Among the four algorithms, Naïve Bayes was found to be more accurate for categorizing app reviews. [Conclusions] The results show that official app changelogs did not contribute to more accurate identification and classification of requirements from app reviews. In addition, Naïve Bayes seems to be more suitable for our further research on this topic.","App reviews, app changelogs, requirements analysis, machine learning, data-driven requirements engineering",International Symposium on Empirical Software Engineering and Measurement,ESEM
3,"Baker, C. Deng, L. Chakraborty, S. Dehlinger, J.",﻿10.1109/COMPSAC.2019.10275,Automatic Multi-class Non-Functional Software Requirements Classification Using Neural Networks,"Advances in machine learning (ML) algorithms, graphics processing units, and readily available ML libraries have enabled the application of ML to open software engineering challenges. Yet, the use of ML to enable decision-making during the software engineering lifecycle is not well understood as there are various ML models requiring parameter tuning. In this paper, we leverage ML techniques to develop an effective approach to classify software requirements. Specifically, we investigate the design and application of two types of neural network models, an artificial neural network (ANN) and a convolutional neural network (CNN), to classify non-functional requirements (NFRs) into the following five categories: maintainability, operability, performance, security and usability. We illustrate and experimentally evaluate this work through two widely used datasets consisting of nearly 1,000 NFRs. Our results indicate that our CNN model can effectively classify NFRs by achieving precision ranging between 82% and 94%, recall ranging between 76% and 97% with an F-score ranging between 82% and 92%.","non-functional requirements, requirements engineering, machine learning",Computer Software and Applications Conference,COMPSAC
4,"Sharma, R. Bhatia, J. Biswas, K K.",﻿10.1109/IAdCC.2014.6779538,Automated identification of business rules in requirements documents,"Business Rule identification is an important task of Requirements Engineering process. However, the task is challenging as business rules are often not explicitly stated in the requirements documents. In case business rules are explicit, they may not be atomic in nature or, may be vague. In this paper, we present an approach for identifying business rules in the available requirements documentation. We first identify various business rules categories and, then examine requirements documentation (including requirements specifications, domain knowledge documents, change request, request for proposal) for the presence of these rules. Our study aims at finding how effectively business rules can be identified and classified into one of the categories of business rules using machine learning algorithms. We report on the results of the experiments performed. Our observations indicate that in terms of overall result, support vector machine algorithm performed better than other classifiers. Random Forest algorithm had a higher precision than support vector machine algorithm but relatively low recall. Naïve Bayes algorithm had a higher recall than support vector machine. We also report on evaluation study of our requirements corpus using stop-words and stemming the requirements statements.","﻿Business Rules, Requirements, Machine Learning",IEEE International Advance Computing Conference,IACC
5,"Dekhtyar, A. Fong, V.",10.1109/RE.2017.26,RE Data Challenge: Requirements Identification with Word2Vec and TensorFlow,"Since their introduction over a year ago, Google's TensorFlow package for learning with multilayer neural networks and their Word2Vec representation of words have both gained a high degree of notoriety. This paper considers the application of TensorFlow-guided learning and Word2Vec-based representations to the problems of classification in requirements documents. In this paper, we compare three categories of machine learning techniques for requirements identification for the SecReq and NFR datasets. The first category is the baseline method used in prior work: Naïve Bayes over word count and TF-IDF representations of requirements. The remaining two categories of techniques are the training of TensorFlow's convolutional neural networks on random and pre-trained Word2Vec embeddings of the words found in the requirements. This paper reports on the experiments we conducted and the accuracy results we achieved.","machine learning, convolutional neural networks, requirements identification, TensorFlow, Word2Vec",International Requirements Engineering Conference,RE
6,"Iqbal, T. Elahidoost, P. Lucio, L.",﻿10.1109/APSEC.2018.00015,A Bird's Eye View on Requirements Engineering and Machine Learning,"Machine learning (ML) has demonstrated practical impact in a variety of application domains. Software engineering is a fertile domain where ML is helping in automating different tasks. In this paper, our focus is the intersection of software requirement engineering (RE) and ML. To obtain an overview of how ML is helping RE and the research trends in this area, we have surveyed a large number of research articles. We found that the impact of ML can be observed in requirement elicitation, analysis and specification, validation and management. Furthermore, in these categories, we discuss the specific problem solved by ML, the features and ML algorithms used as well as datasets, when available. We outline lessons learned and envision possible future directions for the domain.","Requirements Engineering, Machine learning, State of the art, Overview",Asia-Pacific Software Engineering Conference,APSEC
7,"Li, C. Huang, L. Ge, J. Luo, B. Ng, V.",10.1016/j.jss.2017.12.028,Automatically classifying user requests in crowdsourcing requirements engineering,"In order to make a software project succeed, it is necessary to determine the requirements for systems and to document them in a suitable manner. Many ways for requirements elicitation have been discussed. One way is to gather requirements with crowdsourcing methods, which has been discussed for years and is called crowdsourcing requirements engineering. User requests forums in open source communities, where users can propose their expected features of a software product, are common examples of platforms for gathering requirements from the crowd. Requirements collected from these platforms are often informal text descriptions and we name them user requests. In order to transform user requests into structured software requirements, it is better to know the class of requirements that each request belongs to so that each request can be rewritten according to corresponding requirement templates. In this paper, we propose an effective classification methodology by employing both project-specific and non-project-specific keywords and machine learning algorithms. The proposed strategy does well in achieving high classification accuracy by using keywords as features, reducing considerable manual efforts in building machine learning based classifiers, and having stable performance in finding minority classes no matter how few instances they have.","Crowdsourcing requirements engineering, Software requirements classification, Machine learning, Natural language processing",Journal of Systems and Software,
8,"Taj, S. Arain, Q. Memon, I. Zubedi, A.",﻿10.1145/3328833.3328837,To apply Data Mining for Classification of Crowd sourced Software Requirements,"Now a day's main focus of developers is to build quality software that works according to customer needs and for this reason it is necessary to gather right requirements as requirement elicitation is the critical step that impacts on the success of software project as misinterpreted requirements leads to the failure of software project. By keeping this in mind a research is carried out on improving requirements elicitation process and automating the process of classifying requirements. In this research, a model is proposed which will help in this scenario for requirements elicitation and requirement classification. This paper presents a model in which crowd sourcing approach is used so that customers, end users, stakeholders, developers and software engineers can make active participation for requirement elicitation process and requirements gathered using crowdsourcing approach are used by model for classification process i.e. classification of requirements into functional and non-functional requirements. For the proof of proposed model a case study is conducted. Results of case study provided the usefulness and efficiency of proposed model for classification of crowd sourced software requirements.","Crowdsourcing, Requirement elicitation, Data mining, Requirement classification, Functional Requirements, Non-Functional Requirements",International Conference on Software and Information Engineering,ICSIE
9,"Marinho, M. Arruda, D. Wanderley, F. Lins, A.",﻿10.1109/QUATIC.2018.00024,A Systematic Approach of Dataset Definition for a Supervised Machine Learning Using NFR Framework,"Non-functional requirements describe important constraints upon the software development and should therefore be considered and specified as early as possible during the system analysis. Effective elicitation of requirements is arguably among the most important of the resulting recommended RE practices. Recent research has shown that artificial intelligence techniques such as Machine Learning and Text Mining perform the automatic extraction and classification of quality attributes from text documents with relevant results. This paper aims to define a systematic process of dataset generation through NFR Framework catalogues improving the NFR's classification process using Machine Learning techniques. A well-known dataset (Promise) was used to evaluate the precision of our approach reaching interesting results. Regarding to security and performance we obtained a precision and recall ranging between ~85% and ~98%. And we achievement a F1 above ~79% when classified the security, performance and usability together.","non-fucntional requirements, NFR framework, artificial inteligence, machine learning",International Conference on the Quality of Information and Communications Technology,QUATIC
10,"Lu, M. Liang, P.",10.1145/3084226.3084241,Automatic Classification of Non-Functional Requirements from Augmented App User Reviews,"Context: The leading App distribution platforms, Apple App Store, Google Play, and Windows Phone Store, have over 4 million Apps. Research shows that user reviews contain abundant useful information which may help developers to improve their Apps. Extracting and considering Non-Functional Requirements (NFRs), which describe a set of quality attributes wanted for an App and are hidden in user reviews, can help developers to deliver a product which meets users' expectations. Objective: Developers need to be aware of the NFRs from massive user reviews during software maintenance and evolution. Automatic user reviews classification based on an NFR standard provides a feasible way to achieve this goal. Method: In this paper, user reviews were automatically classified into four types of NFRs (reliability, usability, portability, and performance), Functional Requirements (FRs), and Others. We combined four classification techniques BoW, TF-IDF, CHI2, and AUR-BoW (proposed in this work) with three machine learning algorithms Naive Bayes, J48, and Bagging to classify user reviews. We conducted experiments to compare the F-measures of the classification results through all the combinations of the techniques and algorithms. Results: We found that the combination of AUR-BoW with Bagging achieves the best result (a precision of 71.4%, a recall of 72.3%, and an F-measure of 71.8%) among all the combinations. Conclusion: Our finding shows that augmented user reviews can lead to better classification results, and the machine learning algorithm Bagging is more suitable for NFRs classification from user reviews than Naïve Bayes and J48.","Non-Functional Requirements, User Reviews, Automatic Classification, Textual Semantics",International Conference on Evaluation and Assessment in Software Engineering,EASE
11,"Abad, Z S H. Karras, O. Ghazi, P. Glinz, M. Ruhe, G. Schneider, K.",﻿10.1109/RE.2017.36,What Works Better? A Study of Classifying Requirements,"Classifying requirements into functional requirements (FR) and non-functional ones (NFR) is an important task in requirements engineering. However, automated classification of requirements written in natural language is not straightforward, due to the variability of natural language and the absence of a controlled vocabulary. This paper investigates how automated classification of requirements into FR and NFR can be improved and how well several machine learning approaches work in this context. We contribute an approach for preprocessing requirements that standardizes and normalizes requirements before applying classification algorithms. Further, we report on how well several existing machine learning methods perform for automated classification of NFRs into sub-categories such as usability, availability, or performance. Our study is performed on 625 requirements provided by the OpenScience tera-PROMISE repository. We found that our preprocessing improved the performance of an existing classification method. We further found significant differences in the performance of approaches such as Latent Dirichlet Allocation, Biterm Topic Modeling, or Naïve Bayes for the sub-classification of NFRs.","Functional and Non-Functional Requirements, Classification, Topic Modeling, Clustering, NaÏve Bayes",International Requirements Engineering Conference,RE
12,"Riaz, M. King, J. Slankas, J. Williams, L.",﻿10.1109/RE.2014.6912260,Hidden in plain sight: Automatically identifying security requirements from natural language artifacts,"Natural language artifacts, such as requirements specifications, often explicitly state the security requirements for software systems. However, these artifacts may also imply additional security requirements that developers may overlook but should consider to strengthen the overall security of the system. The goal of this research is to aid requirements engineers in producing a more comprehensive and classified set of security requirements by (1) automatically identifying security-relevant sentences in natural language requirements artifacts, and (2) providing context-specific security requirements templates to help translate the security-relevant sentences into functional security requirements. Using machine learning techniques, we have developed a tool-assisted process that takes as input a set of natural language artifacts. Our process automatically identifies security-relevant sentences in the artifacts and classifies them according to the security objectives, either explicitly stated or implied by the sentences. We classified 10,963 sentences in six different documents from healthcare domain and extracted corresponding security objectives. Our manual analysis showed that 46% of the sentences were security-relevant. Of these, 28% explicitly mention security while 72% of the sentences are functional requirements with security implications. Using our tool, we correctly predict and classify 82% of the security objectives for all the sentences (precision). We identify 79% of all security objectives implied by the sentences within the documents (recall). Based on our analysis, we develop context-specific templates that can be instantiated into a set of functional security requirements by filling in key information from security-relevant sentences.","Security, requirements, objectives, templates, access control, auditing, text classification, constraints, natural language parsing.",International Requirements Engineering Conference,RE
13,"Kurtanović, Z. Maalej, W.",﻿10.1109/RE.2017.82,Automatically Classifying Functional and Non-functional Requirements Using Supervised Machine Learning,"In this paper, we take up the second RE17 data challenge: the identification of requirements types using the ""Quality attributes (NFR)"" dataset provided. We studied how accurately we can automatically classify requirements as functional (FR) and non-functional (NFR) in the dataset with supervised machine learning. Furthermore, we assessed how accurately we can identify various types of NFRs, in particular usability, security, operational, and performance requirements. We developed and evaluated a supervised machine learning approach employing meta-data, lexical, and syntactical features. We employed under-and over-sampling strategies to handle the imbalanced classes in the dataset and cross-validated the classifiers using precision, recall, and F1 metrics in a series of experiments based on the Support Vector Machine classifier algorithm. We achieve a precision and recall up to ~92% for automatically identifying FRs and NFRs. For the identification of specific NFRs, we achieve the highest precision and recall for security and performance NFRs with ~92% precision and ~90% recall. We discuss the most discriminating features of FRs and NFRs as well as the sampling strategies used with an additional dataset and their impact on the classification accuracy.","Requirements, Classification, Machine Learning, Imbalanced Data",International Requirements Engineering Conference,RE