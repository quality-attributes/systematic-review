@inproceedings{8719411,
author = {Iqbal, T and Elahidoost, P and L{\'{u}}cio, L},
booktitle = {2018 25th Asia-Pacific Software Engineering Conference (APSEC)},
doi = {10.1109/APSEC.2018.00015},
keywords = {learning (artificial intelligence);problem solving;software engineering;systems analysis;ML;machine learning;software requirement engineering;birds eye view;RE;requirement elicitation;Software;Requirements engineering;Task analysis;Machine learning;Cancer;Machine learning algorithms;Databases;Requirements Engineering;Machine learning;State of the art;Overview},
month = {dec},
pages = {11--20},
title = {{A Bird's Eye View on Requirements Engineering and Machine Learning}},
year = {2018}
}
@inproceedings{LopesSilva:2015:DTS:2695664.2695928,
address = {New York, NY, USA},
author = {{Lopes Silva}, Italo Carlo and Brito, Patrick H S and {dos S. Neto}, Baldoino F and Costa, Evandro and Silva, Andre Almeida},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
doi = {10.1145/2695664.2695928},
isbn = {978-1-4503-3196-8},
keywords = { recommender systems, software architecture,architectural decision},
pages = {1457--1463},
publisher = {ACM},
series = {SAC '15},
title = {{A Decision-making Tool to Support Architectural Designs Based on Quality Attributes}},
url = {http://doi.acm.org/10.1145/2695664.2695928},
year = {2015}
}
@inproceedings{7557524,
author = {Wang, P and Lin, S and Luo, M},
booktitle = {2016 IEEE International Conference on Services Computing (SCC)},
doi = {10.1109/SCC.2016.133},
keywords = {learning (artificial intelligence);quality of service;software defined networking;QoS aware traffic classification framework;semisupervised machine learning;SDN;software defined networks;network traffic;QoS aware traffic engineering;network controller;deep packet inspection;DPI;Quality of service;Real-time systems;Engines;Training;Control systems;Classification algorithms;Support vector machines;Traffic classification;SDN;QoS;Semi-supervised},
month = {jun},
pages = {760--765},
title = {{A Framework for QoS-aware Traffic Classification Using Semi-supervised Machine Learning in SDNs}},
year = {2016}
}
@inproceedings{8048886,
author = {Guzman, E and Ibrahim, M and Glinz, M},
booktitle = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2017.88},
keywords = {data mining;learning (artificial intelligence);social networking (online);software engineering;software applications;software evolution;end-user requirements;requirements engineering;software practitioners;social networks;ranking tweet filtering;ALERTme approach;tweet mining;semantically related tweet grouping;Twitter;Software;Twitter;Data mining;Machine learning algorithms;Computer bugs;Classification algorithms;user feedback;Twitter;software evolution;text mining;requirements elicitation},
pages = {11--20},
title = {{A Little Bird Told Me: Mining Tweets for Requirements and Software Evolution}},
year = {2017}
}
@article{PARRA2015180,
abstract = {Context
One of the most important factors in the development of a software project is the quality of their requirements. Erroneous requirements, if not detected early, may cause many serious problems, such as substantial additional costs, failure to meet the expected objectives and delays in delivery dates. For these reasons, great effort must be devoted in requirements engineering to ensure that the project's requirements results are of high quality. One of the aims of this discipline is the automatic processing of requirements for assessing their quality; this aim, however, results in a complex task because the quality of requirements depends mostly on the interpretation of experts and the necessities and demands of the project at hand.
Objective
The objective of this paper is to assess the quality of requirements automatically, emulating the assessment that a quality expert of a project would assess.
Method
The proposed methodology is based on the idea of learning based on standard metrics that represent the characteristics that an expert takes into consideration when deciding on the good or bad quality of requirements. Using machine learning techniques, a classifier is trained with requirements earlier classified by the expert, which then is used for classifying newly provided requirements.
Results
We present two approaches to represent the methodology with two situations of the problem in function of the requirement corpus learning balancing, obtaining different results in the accuracy and the efficiency in order to evaluate both representations. The paper demonstrates the reliability of the methodology by presenting a case study with requirements provided by the Requirements Working Group of the INCOSE organization.
Conclusions
A methodology that evaluates the quality of requirements written in natural language is presented in order to emulate the quality that the expert would provide for new requirements, with 86.1 of average in the accuracy.},
author = {Parra, Eugenio and Dimou, Christos and Llorens, Juan and Moreno, Valent{\'{i}}n and Fraga, Anabel},
doi = {https://doi.org/10.1016/j.infsof.2015.07.006},
issn = {0950-5849},
journal = {Information and Software Technology},
keywords = { Machine learning, Requirements engineering, Requirements quality,Software engineering},
pages = {180--195},
title = {{A methodology for the classification of quality of requirements using machine learning techniques}},
url = {http://www.sciencedirect.com/science/article/pii/S0950584915001299},
volume = {67},
year = {2015}
}
@inproceedings{7765515,
author = {Guzman, E and Alkadhi, R and Seyff, N},
booktitle = {2016 IEEE 24th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2016.67},
keywords = {DP industry;learning (artificial intelligence);pattern classification;social networking (online);software engineering;statistical analysis;Twitter microblogging platform;tweets;software companies;software applications;automatic classification potential;descriptive statistics;content analysis;machine learning;Software;Twitter;Companies;Stakeholders;Automation;Requirements engineering;Needles},
pages = {96--105},
title = {{A Needle in a Haystack: What Do Twitter Users Say about Software?}},
year = {2016}
}
@inproceedings{8590177,
author = {Marinho, M and Arruda, D and Wanderley, F and Lins, A},
booktitle = {2018 11th International Conference on the Quality of Information and Communications Technology (QUATIC)},
doi = {10.1109/QUATIC.2018.00024},
keywords = {data mining;formal specification;formal verification;learning (artificial intelligence);pattern classification;systems analysis;text analysis;systematic approach;dataset definition;nonfunctional requirements;software development;system analysis;artificial intelligence techniques;automatic extraction;text documents;systematic process;dataset generation;NFR's classification process;text mining;supervised machine learning techniques;Machine learning;Systematics;Security;Requirements engineering;Usability;non-fucntional requirements;NFR framework;artificial inteligence;machine learning;SIG},
pages = {110--118},
title = {{A Systematic Approach of Dataset Definition for a Supervised Machine Learning Using NFR Framework}},
year = {2018}
}
@inproceedings{Wever:2017:ACL:3071178.3071258,
address = {New York, NY, USA},
author = {Wever, Marcel and van Rooijen, Lorijn and Hamann, Heiko},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
doi = {10.1145/3071178.3071258},
isbn = {978-1-4503-4920-8},
keywords = { interactive evolution, multi-objective optimization, software engineering,co-evolution},
pages = {1327--1334},
publisher = {ACM},
series = {GECCO '17},
title = {{Active Coevolutionary Learning of Requirements Specifications from Examples}},
url = {http://doi.acm.org/10.1145/3071178.3071258},
year = {2017}
}
@inproceedings{Osman:2018:ASR:3195538.3195545,
address = {New York, NY, USA},
author = {Osman, Mohd Hafeez and Zaharin, Mohd Firdaus},
booktitle = {Proceedings of the 5th International Workshop on Requirements Engineering and Testing},
doi = {10.1145/3195538.3195545},
isbn = {978-1-4503-5749-4},
keywords = { requirement engineering, software engineering, text mining,machine learning},
pages = {33--40},
publisher = {ACM},
series = {RET '18},
title = {{Ambiguous Software Requirement Specification Detection: An Automated Approach}},
url = {http://doi.acm.org/10.1145/3195538.3195545},
year = {2018}
}
@inproceedings{8320253,
author = {Singh, M and Walia, G S and Goswami, A},
booktitle = {2017 International Conference on Machine Learning and Data Science (MLDS)},
doi = {10.1109/MLDS.2017.15},
keywords = {inspection;learning (artificial intelligence);pattern classification;software fault tolerance;software inspection results;machine learning techniques;raw data;class imbalance problem;false-positive reviews;class-imbalance;fault-slippage;fault misclassification;inspection review classification;Inspection;Motion pictures;Training;Testing;Software;Speech;Natural languages;Fault priority;class imbalance;ensemble;sampling;inspections reviews;part of speech;machine learning;fault slippage},
month = {dec},
pages = {15--22},
title = {{An Empirical Investigation to Overcome Class-Imbalance in Inspection Reviews}},
year = {2017}
}
@article{Yang2011,
abstract = {Many requirements documents are written in natural language (NL). However, with the flexibility of NL comes the risk of introducing unwanted ambiguities in the requirements and misunderstandings between stakeholders. In this paper, we describe an automated approach to identify potentially nocuous ambiguity, which occurs when text is interpreted differently by different readers. We concentrate on anaphoric ambiguity, which occurs when readers may disagree on how pronouns should be interpreted. We describe a number of heuristics, each of which captures information that may lead a reader to favor a particular interpretation of the text. We use these heuristics to build a classifier, which in turn predicts the degree to which particular interpretations are preferred. We collected multiple human judgements on the interpretation of requirements exhibiting anaphoric ambiguity and showed how the distribution of these judgements can be used to assess whether a particular instance of ambiguity is nocuous. Given a requirements document written in natural language, our approach can identify sentences that contain anaphoric ambiguity, and use the classifier to alert the requirements writer of text that runs the risk of misinterpretation. We report on a series of experiments that we conducted to evaluate the performance of the automated system we developed to support our approach. The results show that the system achieves high recall with a consistent improvement on baseline precision subject to some ambiguity tolerance levels, allowing us to explore and highlight realistic and potentially problematic ambiguities in actual requirements documents.},
author = {Yang, Hui and de Roeck, Anne and Gervasi, Vincenzo and Willis, Alistair and Nuseibeh, Bashar},
doi = {10.1007/s00766-011-0119-y},
issn = {1432-010X},
journal = {Requirements Engineering},
month = {may},
number = {3},
pages = {163},
title = {{Analysing anaphoric ambiguity in natural language requirements}},
url = {https://doi.org/10.1007/s00766-011-0119-y},
volume = {16},
year = {2011}
}
@inproceedings{6636705,
author = {Sultanov, H and Hayes, J H},
booktitle = {2013 21st IEEE International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2013.6636705},
keywords = {formal verification;learning (artificial intelligence);program diagnostics;reinforcement learning;requirements engineering;requirements traceability method;machine learning technique;RL method;textual requirements artifacts;Learning (artificial intelligence);Software;Navigation;Vocabulary;Joining processes;Educational institutions;machine learning;reinforcement learning;information retrieval;requirements traceability;software engineering;Ubiquitous Grand Challenge;Research Project 2 of Grand Challenges of Traceability},
month = {jul},
pages = {52--61},
title = {{Application of reinforcement learning to requirements engineering: requirements tracing}},
year = {2013}
}
@inproceedings{Alebrahim:2015:APP:2855321.2855357,
address = {New York, NY, USA},
author = {Alebrahim, Azadeh and Heisel, Maritta},
booktitle = {Proceedings of the 20th European Conference on Pattern Languages of Programs},
doi = {10.1145/2855321.2855357},
isbn = {978-1-4503-3847-9},
keywords = { performance patterns, problem frames, requirements engineering, software architecture,UML},
pages = {35:1----35:15},
publisher = {ACM},
series = {EuroPLoP '15},
title = {{Applying Performance Patterns for Requirements Analysis}},
url = {http://doi.acm.org/10.1145/2855321.2855357},
year = {2015}
}
@inproceedings{7732349,
author = {Jindal, R and Malhotra, R and Jain, A},
booktitle = {2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
doi = {10.1109/ICACCI.2016.7732349},
keywords = {authorisation;cryptography;data integrity;decision trees;formal specification;message authentication;text analysis;automated classification;security requirements;requirement engineers;software requirement specification;SRS document;text mining techniques;authentication-authorization;access control;cryptography-encryption;data integrity;J48 decision tree method;Software;Predictive models;Text mining;Access control;Cryptography;Analytical models;Non-functional requirements;Text mining;Machine learning;Security requirements;Requirement engineering;Requirement elicitation;Receiver Operating Characteristics},
pages = {2027--2033},
title = {{Automated classification of security requirements}},
year = {2016}
}
@inproceedings{6779538,
author = {Sharma, R and Bhatia, J and Biswas, K K},
booktitle = {2014 IEEE International Advance Computing Conference (IACC)},
doi = {10.1109/IAdCC.2014.6779538},
keywords = {Bayes methods;business data processing;formal specification;learning (artificial intelligence);natural language processing;support vector machines;systems analysis;text analysis;trees (mathematics);automated business rule identification;requirements engineering process;requirements documentation;business rules categories;requirement specifications;domain knowledge documents;change request;request for proposal;machine learning algorithm;support vector machine algorithm;random forest algorithm;naive Bayes algorithm;requirements corpus;stop-words;requirement statements;Classification algorithms;Information systems;Machine learning algorithms;Organizations;Documentation;Support vector machines;Business Rules;Requirements;Machine Learning},
month = {feb},
pages = {1442--1447},
title = {{Automated identification of business rules in requirements documents}},
year = {2014}
}
@inproceedings{8609673,
author = {Atas, M and Samer, R and Felfernig, A},
booktitle = {2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)},
doi = {10.1109/WI.2018.00-10},
keywords = { classification techniques, content-aware analytics, data science, machine learning, requirements engineering,Bayes methods;formal specification;learning (artificial intelligence);nearest neighbour methods;pattern classification;random forests;software engineering;support vector machines;automated identification;type-specific dependencies;requirement dependencies;requirements engineering;textual level;software project;random forest;k-nearest neighbors;Linear SVM;Naive Bayes classifier;Software;Requirements engineering;Stakeholders;Natural language processing;Sports;Time measurement;Global Positioning System;meta knowledge discovery and representation},
month = {dec},
pages = {688--695},
title = {{Automated Identification of Type-Specific Dependencies between Requirements}},
year = {2018}
}
@inproceedings{8491169,
author = {Singh, M},
booktitle = {2018 IEEE 26th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2018.00062},
keywords = {data mining;formal specification;graph theory;inspection;learning (artificial intelligence);natural language processing;program diagnostics;software development management;software fault tolerance;software quality;requirement reviews;software development;fuzzy phases;software inspections;design artifacts;fault propagation;inspection process;software requirements specification document;actual development work;inspection reviews;high-quality requirements;fault prone requirements pre-inspection;interrelated requirements;reported faults post-inspection;NL processing;NL requirements;post-inspection decisions;Inspection;Software;Semantics;Fault diagnosis;Analytical models;Data mining;Natural languages;requirement inspections;classification;semantic analysis;topic modeling;high quality requirements;interrelated requirements;part of speech tags},
month = {aug},
pages = {460--465},
title = {{Automated Validation of Requirement Reviews: A Machine Learning Approach}},
year = {2018}
}
@inproceedings{Lu:2017:ACN:3084226.3084241,
address = {New York, NY, USA},
author = {Lu, Mengmeng and Liang, Peng},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
doi = {10.1145/3084226.3084241},
isbn = {978-1-4503-4804-1},
keywords = { Non-Functional Requirements, Textual Semantics, User Reviews,Automatic Classification},
pages = {344--353},
publisher = {ACM},
series = {EASE'17},
title = {{Automatic Classification of Non-Functional Requirements from Augmented App User Reviews}},
url = {http://doi.acm.org/10.1145/3084226.3084241},
year = {2017}
}
@inproceedings{7815604,
author = {Winkler, J and Vogelsang, A},
booktitle = {2016 IEEE 24th International Requirements Engineering Conference Workshops (REW)},
doi = {10.1109/REW.2016.021},
keywords = {convolution;formal specification;natural languages;neural nets;pattern classification;automatic requirements classification;convolutional neural networks;requirements engineering;natural language requirements specifications;automatic content elements classification;real-world automotive requirements specification;Neural networks;Industries;Natural language processing;Training;Data mining;Conferences;Requirements engineering;convolutional neural networks;machine learning;quality assurance;classification},
pages = {39--45},
title = {{Automatic Classification of Requirements Based on Convolutional Neural Networks}},
year = {2016}
}
@inproceedings{8714682,
author = {Riaz, M Q and Butt, W H and Rehman, S},
booktitle = {2019 5th International Conference on Information Management (ICIM)},
doi = {10.1109/INFOMAN.2019.8714682},
keywords = {formal specification;natural language processing;software quality;systems analysis;development phase;automatic detection;natural language ambiguities;software requirement documents;ambiguous software requirements;Requirements Engineering;software development lifecycle;software project;Software;Tools;Natural language processing;Documentation;Knowledge based systems;Machine learning;natural language requirement;requirement engineering;ambiguity;natural language ambiguity;ambiguous software requirements;natural language processing},
month = {mar},
pages = {1--6},
title = {{Automatic Detection of Ambiguous Software Requirements: An Insight}},
year = {2019}
}
@inproceedings{8754214,
author = {Baker, C and Deng, L and Chakraborty, S and Dehlinger, J},
booktitle = {2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)},
doi = {10.1109/COMPSAC.2019.10275},
keywords = {convolutional neural nets;formal specification;learning (artificial intelligence);software quality;CNN model;automatic multiclass nonfunctional software requirements classification;neural networks;machine learning;software engineering lifecycle;ML models;neural network models;artificial neural network;convolutional neural network;nonfunctional requirements;NFR;Software;Conferences;non-functional requirements;requirements engineering;machine learning},
month = {jul},
pages = {610--615},
title = {{Automatic Multi-class Non-Functional Software Requirements Classification Using Neural Networks}},
volume = {2},
year = {2019}
}
@article{Wang2016,
abstract = {Nowadays, software requirements are still mainly analyzed manually, which has many drawbacks (such as a large amount of labor consumption, inefficiency, and even inaccuracy of the results). The problems are even worse in domain analysis scenarios because a large number of requirements from many users need to be analyzed. In this sense, automatic analysis of software requirements can bring benefits to software companies. For this purpose, we proposed an approach to automatically analyze software requirement specifications (SRSs) and extract the semantic information. In this approach, a machine learning and ontology based semantic role labeling (SRL) method was used. First of all, some common verbs were calculated from SRS documents in the E-commerce domain, and then semantic frames were designed for those verbs. Based on the frames, sentences from SRSs were selected and labeled manually, and the labeled sentences were used as training examples in the machine learning stage. Besides the training examples labeled with semantic roles, external ontology knowledge was used to relieve the data sparsity problem and obtain reliable results. Based on the SemCor and WordNet corpus, the senses of nouns and verbs were identified in a sequential manner through the K-nearest neighbor approach. Then the senses of the verbs were used to identify the frame types. After that, we trained the SRL labeling classifier with the maximum entropy method, in which we added some new features based on word sense, such as the hypernyms and hyponyms of the word senses in the ontology. Experimental results show that this new approach for automatic functional requirements analysis is effective.},
author = {Wang, Yinglin},
doi = {10.1007/s12204-016-1783-3},
issn = {1995-8188},
journal = {Journal of Shanghai Jiaotong University (Science)},
month = {dec},
number = {6},
pages = {692--701},
title = {{Automatic semantic analysis of software requirements through machine learning and ontology approach}},
url = {https://doi.org/10.1007/s12204-016-1783-3},
volume = {21},
year = {2016}
}
@inproceedings{8049171,
author = {Kurtanovi{\'{c}}, Z and Maalej, W},
booktitle = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2017.82},
keywords = {learning (artificial intelligence);meta data;pattern classification;support vector machines;systems analysis;text analysis;nonfunctional requirements;supervised machine learning;RE17 data challenge;performance requirements;classifiers;Support Vector Machine classifier algorithm;security;meta-data;automatically requirements classification;quality attributes;lexical features;syntactical features;sampling strategies;Training;Usability;Security;Feature extraction;Vegetation;Support vector machines;Requirements;Classification;Machine Learning;Imbalanced Data},
pages = {490--495},
title = {{Automatically Classifying Functional and Non-functional Requirements Using Supervised Machine Learning}},
year = {2017}
}
@article{LI2018108,
abstract = {In order to make a software project succeed, it is necessary to determine the requirements for systems and to document them in a suitable manner. Many ways for requirements elicitation have been discussed. One way is to gather requirements with crowdsourcing methods, which has been discussed for years and is called crowdsourcing requirements engineering. User requests forums in open source communities, where users can propose their expected features of a software product, are common examples of platforms for gathering requirements from the crowd. Requirements collected from these platforms are often informal text descriptions and we name them user requests. In order to transform user requests into structured software requirements, it is better to know the class of requirements that each request belongs to so that each request can be rewritten according to corresponding requirement templates. In this paper, we propose an effective classification methodology by employing both project-specific and non-project-specific keywords and machine learning algorithms. The proposed strategy does well in achieving high classification accuracy by using keywords as features, reducing considerable manual efforts in building machine learning based classifiers, and having stable performance in finding minority classes no matter how few instances they have.},
author = {Li, Chuanyi and Huang, Liguo and Ge, Jidong and Luo, Bin and Ng, Vincent},
doi = {https://doi.org/10.1016/j.jss.2017.12.028},
issn = {0164-1212},
journal = {Journal of Systems and Software},
keywords = { Machine learning, Natural language processing, Software requirements classification,Crowdsourcing requirements engineering},
pages = {108--123},
title = {{Automatically classifying user requests in crowdsourcing requirements engineering}},
url = {http://www.sciencedirect.com/science/article/pii/S0164121217303096},
volume = {138},
year = {2018}
}
@inproceedings{8595127,
author = {Dekhtyar, A and Hayes, J H},
booktitle = {2018 1st International Workshop on Learning from other Disciplines for Requirements Engineering (D4RE)},
doi = {10.1109/D4RE.2018.00009},
keywords = { information retrieval, knowledge discovery from data, traceability,data mining;information retrieval;learning (artificial intelligence);requirements traceability;data methodology;knowledge discovery in data;KDD;Software;Software engineering;Information retrieval;Conferences;Requirements engineering;Machine learning;Area measurement;requirements tracing},
month = {aug},
pages = {12--15},
title = {{Automating Requirements Traceability: Two Decades of Learning from KDD}},
year = {2018}
}
@article{del√Åguila2016,
abstract = {Requirements analysis is the software engineering stage that is closest to the users' world. It also involves tasks that are knowledge intensive. Thus, the use of Bayesian networks (BNs) to model this knowledge would be a valuable aid. These probabilistic models could manage the imprecision and ambiguities usually present in requirements engineering (RE). In this work, we conduct a literature review focusing on where and how BNs are applied on subareas of RE in order to identify which gaps remain uncovered and which methods might engineers employ to incorporate this intelligent technique into their own requirements processes. The scarcity of identified studies (there are only 20) suggests that not all RE areas have been properly investigated in the literature. The evidence available for adopting BNs into RE is sufficiently mature yet the methods applied are not easily translatable to other topics. Nonetheless, there are enough studies supporting the applicability of synergistic cooperation between RE and BNs. This work provides a background for understanding the current state of research encompassing RE and BNs. Functional, non-functional and -ilities requirements artifacts are enhanced by the use of BNs. These models were obtained by interacting with experts or by learning from databases. The most common criticism from the point of view of BN experts is that the models lack validation, whereas requirements engineers point to the lack of a clear application method for BNs and the lack of tools for incorporating them as built-in help functions.},
author = {del {\'{A}}guila, Isabel M and del Sagrado, Jos{\'{e}}},
doi = {10.1007/s00766-015-0225-3},
issn = {1432-010X},
journal = {Requirements Engineering},
month = {nov},
number = {4},
pages = {461--480},
title = {{Bayesian networks for enhancement of requirements engineering: a literature review}},
url = {https://doi.org/10.1007/s00766-015-0225-3},
volume = {21},
year = {2016}
}
@inproceedings{7320414,
author = {Maalej, W and Nabil, H},
booktitle = {2015 IEEE 23rd International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2015.7320414},
keywords = {data mining;natural language processing;pattern classification;probability;software reviews;string matching;text analysis;bug report;app reviews classification;App stores;Google Play;Apple AppStore;several probabilistic techniques;review metadata;star rating;user experiences;feature requests;text classification;natural language processing;sentiment analysis techniques;string matching;multiple binary classifiers;multiclass classifiers;review analytics tool design;Metadata;Google;Accuracy;Training;Computer crashes;Natural language processing;Machine learning algorithms},
month = {aug},
pages = {116--125},
title = {{Bug report, feature request, or simply praise? On automatically classifying app reviews}},
year = {2015}
}
@inproceedings{Wang:2018:ACI:3239235.3267428,
address = {New York, NY, USA},
author = {Wang, Chong and Zhang, Fan and Liang, Peng and Daneva, Maya and van Sinderen, Marten},
booktitle = {Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
doi = {10.1145/3239235.3267428},
isbn = {978-1-4503-5823-1},
keywords = { app reviews, data-driven requirements engineering, machine learning, requirements analysis,app changelogs},
pages = {43:1----43:4},
publisher = {ACM},
series = {ESEM '18},
title = {{Can App Changelogs Improve Requirements Classification from App Reviews?: An Exploratory Study}},
url = {http://doi.acm.org/10.1145/3239235.3267428},
year = {2018}
}
@article{GUPTA2018,
abstract = {The success of requirement prioritization process largely depends upon how well different constraints and influential factors are handled by stakeholders and developers while prioritization. The main goal of this research is to present a semi-automated dependency based collaborative requirement prioritization approach (CDBR), which uses linguistic values, execute-before-after (EBA) relation among requirements and machine learning algorithm to minimize the difference of opinion between stakeholder and developers for effective collaboration and for better approximation of final prioritization results, acceptable to both. The presented approach targets three major constraints rarely addressed in existing work, namely dependencies among requirements, communication among stakeholder and developers and the issue of scalability. Results of performance assessment conducted on several different requirement sets and on a case study by comparing CDBR with other state of the art approaches namely, AHP and IGA. The results are accurate and comparable in terms of effectiveness, efficiency, scalability and disagreement concerns among stakeholder and developers which in turn provides robustness to decision making process of awarding more importance to some requirements over others. CDBR overpowers AHP and IGA in terms of efficiency and processing time respectively.},
author = {Gupta, Ankita and Gupta, Chetna},
doi = {https://doi.org/10.1016/j.jksuci.2018.10.004},
issn = {1319-1578},
journal = {Journal of King Saud University - Computer and Information Sciences},
keywords = { Machine learning, Requirement engineering, Requirements dependency, Requirements prioritization,Collaboration},
title = {{CDBR: A semi-automated collaborative execute-before-after dependency-based requirement prioritization approach}},
url = {http://www.sciencedirect.com/science/article/pii/S1319157818304518},
year = {2018}
}
@article{Ferrari2018,
abstract = {In the railway safety-critical domain requirements documents have to abide to strict quality criteria. Rule-based natural language processing (NLP) techniques have been developed to automatically identify quality defects in natural language requirements. However, the literature is lacking empirical studies on the application of these techniques in industrial settings. Our goal is to investigate to which extent NLP can be practically applied to detect defects in the requirements documents of a railway signalling manufacturer. To address this goal, we first identified a set of typical defects classes, and, for each class, an engineer of the company implemented a set of defect-detection patterns by means of the GATE tool for text processing. After a preliminary analysis, we applied the patterns to a large set of 1866 requirements previously annotated for defects. The output of the patterns was further inspected by two domain experts to check the false positive cases. Additional discard-patterns were defined to automatically remove these cases. Finally, SREE, a tool that searches for typically ambiguous terms, was applied to the requirements. The experiments show that SREE and our patterns may play complementary roles in the detection of requirements defects. This is one of the first works in which defect detection NLP techniques are applied on a very large set of industrial requirements annotated by domain experts. We contribute with a comparison between traditional manual techniques used in industry for requirements analysis, and analysis performed with NLP. Our experience shows that several discrepancies can be observed between the two approaches. The analysis of the discrepancies offers hints to improve the capabilities of NLP techniques with company specific solutions, and suggests that also company practices need to be modified to effectively exploit NLP tools.},
author = {Ferrari, Alessio and Gori, Gloria and Rosadini, Benedetta and Trotta, Iacopo and Bacherini, Stefano and Fantechi, Alessandro and Gnesi, Stefania},
doi = {10.1007/s10664-018-9596-7},
issn = {1573-7616},
journal = {Empirical Software Engineering},
month = {dec},
number = {6},
pages = {3684--3733},
title = {{Detecting requirements defects with NLP patterns: an industrial experience in the railway domain}},
url = {https://doi.org/10.1007/s10664-018-9596-7},
volume = {23},
year = {2018}
}
@inproceedings{8054881,
author = {van Rooijen, L and B{\"{a}}umer, F S and Platenius, M C and Geierhos, M and Hamann, H and Engels, G},
booktitle = {2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)},
doi = {10.1109/REW.2017.26},
keywords = {formal specification;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);software development management;systems analysis;untrained users;trained users;formal requirements models;requirements engineering;unstructured natural language description;behavioral descriptions;behavioral ontologies;search-based technique;software deployment process automation;software development process automation;software service markets;Software;Unified modeling language;Requirements engineering;Ontologies;Search problems;Natural languages},
pages = {379--385},
title = {{From User Demand to Software Service: Using Machine Learning to Automate the Requirements Specification Process}},
year = {2017}
}
@article{Groen2019,
author = {Groen, Eduard C and Harrison, Rachel and Murukannaiah, Pradeep K and Vogelsang, Andreas},
doi = {10.1007/s10515-019-00262-6},
issn = {1573-7535},
journal = {Automated Software Engineering},
month = {sep},
number = {3},
pages = {511--512},
title = {{Guest editorial: special section on artificial intelligence for requirements engineering}},
url = {https://doi.org/10.1007/s10515-019-00262-6},
volume = {26},
year = {2019}
}
@inproceedings{6912260,
author = {Riaz, M and King, J and Slankas, J and Williams, L},
booktitle = {2014 IEEE 22nd International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2014.6912260},
keywords = {formal specification;learning (artificial intelligence);natural language processing;security of data;natural language artifacts;requirements specifications;software systems;requirements engineer;security-relevant sentences;natural language requirements artifacts;context-specific security requirements templates;functional security requirements;machine learning techniques;tool-assisted process;security objectives;healthcare domain;functional requirements;context-specific templates;Security;Natural languages;Object recognition;Software systems;Availability;Medical services;Text categorization;Security;requirements;objectives;templates;access control;auditing;text classification;constraints;natural language parsing},
month = {aug},
pages = {183--192},
title = {{Hidden in plain sight: Automatically identifying security requirements from natural language artifacts}},
year = {2014}
}
@article{Zou2010,
abstract = {Automated requirements traceability methods that utilize Information Retrieval (IR) methods to generate and maintain traceability links are often more efficient than traditional manual approaches, however the traces they generate are imprecise and significant human effort is needed to evaluate and filter the results. This paper investigates and compares three term-based enhancement methods that are designed to improve the performance of a probabilistic automated tracing tool. Empirical studies show that the enhancement methods can be effective in increasing the accuracy of the retrieved traces; however the effectiveness of each method varies according to specific project characteristics. The analysis of such characteristics has lead to the development of two new project-level metrics which can be used to predict the effectiveness of each enhancement method for a given data set. A procedure to automatically extract critical keywords and phrases from a set of traceable artifacts is also presented to enhance the automated trace retrieval algorithm. The procedure is tested on two new datasets.},
author = {Zou, Xuchang and Settimi, Raffaella and Cleland-Huang, Jane},
doi = {10.1007/s10664-009-9114-z},
issn = {1573-7616},
journal = {Empirical Software Engineering},
month = {apr},
number = {2},
pages = {119--146},
title = {{Improving automated requirements trace retrieval: a study of term-based enhancement methods}},
url = {https://doi.org/10.1007/s10664-009-9114-z},
volume = {15},
year = {2010}
}
@inproceedings{8049156,
author = {Noaeen, M and Abad, Z S H and Far, B H},
booktitle = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2017.78},
keywords = {Android (operating system);Bayes methods;formal specification;graphical user interfaces;learning (artificial intelligence);natural language processing;pattern classification;systems analysis;traffic engineering computing;TM domain;software development;transportation engineering;software systems;nonfunctional requirements;software-reliant systems;RETTA tool;machine learning approaches;Natural Language Processing;requirements engineering;requirements elicitation tool-for-traffic management systems;functional requirements;na{\"{i}}ve Bayes method;Android-based devices;Tools;Transportation;Complexity theory;Data analysis;Prototypes;Computational modeling;Requirements engineering;Requirements Engineering;Transportation Management;Tool Development;Traffic Signal Timing},
pages = {450--451},
title = {{Let's Hear it from RETTA: A Requirements Elicitation Tool for TrAffic Management Systems}},
year = {2017}
}
@inproceedings{7883431,
author = {Alrajeh, D and Russo, A and Uchitel, S and Kramer, J},
booktitle = {2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)},
keywords = {formal specification;formal verification;learning (artificial intelligence);pattern classification;pattern clustering;regression analysis;logic-based learning;software engineering;machine learning;ML techniques;program repair;specification mining;risk assessment;software models;declarative rule-based manner;requirements engineering;software design;Software engineering;Requirements engineering;Maintenance engineering;Learning systems;Software systems;Computational modeling},
month = {may},
pages = {892--893},
title = {{Logic-Based Learning in Software Engineering}},
year = {2016}
}
@article{Casamayor2012,
abstract = {Modern Software Engineering (SE) is characterized by the use of several models that establish and show the different states a software product goes through, from its initial conception to its end, passing across its development, setup and maintenance among others. Each phase produces a set of deliverables following different documentation standards, but in many cases, natural language text is a key aspect in the elaboration of such documents. This work surveys the state of the art in the application of text mining techniques to architectural software design, starting from the role of text documents during development phases, specifically the kind of text documents that can be subsequently exploited to assist architects in the complex task of designing software. Intelligent text analysis techniques utilized in software engineering tasks across the software life-cycle are detailed in order to analyze works focused on automatically bridging the gap between requirements and software architectures.},
author = {Casamayor, Agustin and Godoy, Daniela and Campo, Marcelo},
doi = {10.1007/s10462-011-9237-7},
issn = {1573-7462},
journal = {Artificial Intelligence Review},
month = {oct},
number = {3},
pages = {173--191},
title = {{Mining textual requirements to assist architectural software design: a state of the art review}},
url = {https://doi.org/10.1007/s10462-011-9237-7},
volume = {38},
year = {2012}
}
@article{Belsis2014,
abstract = {Agile software development methodologies are increasingly adopted by organizations because they focus on the client's needs, thus safeguarding business value for the final product. At the same time, as the economy and society move toward globalization, more organizations shift to distributed development of software projects. From this perspective, while adopting agile techniques seems beneficial, there are still a number of challenges that need to be addressed; among these notable is the effective cooperation between the stakeholders and the geographically distributed development team. In addition, data collection and validation for requirements engineering demands efficient processing techniques in order to handle the volume of data as well as to manage different inconsistencies, when the data are collected using online tools. In this paper, we present ``PBURC,'' a patterns-based, unsupervised requirements clustering framework, which makes use of machine-learning methods for requirements validation, being able to overcome data inconsistencies and effectively determine appropriate requirements clusters for optimal definition of software development sprints.},
author = {Belsis, Petros and Koutoumanos, Anastasios and Sgouropoulou, Cleo},
doi = {10.1007/s00766-013-0172-9},
issn = {1432-010X},
journal = {Requirements Engineering},
month = {jun},
number = {2},
pages = {213--225},
title = {{PBURC: a patterns-based, unsupervised requirements clustering framework for distributed agile software development}},
url = {https://doi.org/10.1007/s00766-013-0172-9},
volume = {19},
year = {2014}
}
@article{Serral2018,
abstract = {Pervasive environments are socio-technical systems that support the daily routines of their users in an invisible and unobtrusive manner. These systems are aware of and adapt to both the operational context and the characteristics and preferences of their users. Designing adaptation mechanisms that guarantee maximal user satisfaction is challenging, due to the inherent differences between users and the changing context where the system operates. In order to tackle this problem, we propose an approach that compares alternative system behaviors in terms of how well they satisfy the preferences of the current user concerning Non-Functional Requirements (NFRs) such as efficiency, comfort, energy saving, etc. Specifically, we propose a model-driven framework in which the models represent the user routines that the pervasive system helps to achieve. These routines include variability points, thereby enabling their behavior to be adapted at runtime in order to fit the context and the user preferences over NFRs. Our contributions include: (1) user-adaptive task models, a modeling language to describe user routines that accounts for user preferences over NFRs; (2) algorithms that use our models at runtime to guide a pervasive system in adapting its behavior to user preferences and context; and (3) an implementation and evaluation of our techniques.},
author = {Serral, Estefan{\'{i}}a and Sernani, Paolo and Dalpiaz, Fabiano},
doi = {10.1007/s12652-017-0611-4},
issn = {1868-5145},
journal = {Journal of Ambient Intelligence and Humanized Computing},
month = {nov},
number = {6},
pages = {1729--1743},
title = {{Personalized adaptation in pervasive systems via non-functional requirements}},
url = {https://doi.org/10.1007/s12652-017-0611-4},
volume = {9},
year = {2018}
}
@inproceedings{8786652,
author = {Ebrahimi, A M and Barforoush, A A},
booktitle = {2019 27th Iranian Conference on Electrical Engineering (ICEE)},
doi = {10.1109/IranianCEE.2019.8786652},
keywords = {information analysis;learning (artificial intelligence);social networking (online);software engineering;requirements-related tweets;crowdsourcing software requirements;technical stakeholders;software products;software users;machine learning;learning techniques;supervised learning algorithms;natural language processing approach;tweet analysis;Software;Twitter;Computer bugs;Terminology;Electrical engineering;Tagging;Stakeholders;Twitter;User Feedback;Crowd RE;Requirement Elicitation;Data-driven Requirements Engineering;Software Evolution;Text Preprocessing},
month = {apr},
pages = {1905--1911},
title = {{Preprocessing Role in Analyzing Tweets Towards Requirement Engineering}},
year = {2019}
}
@inproceedings{Alebrahim:2014:PSP:2721956.2721963,
address = {New York, NY, USA},
author = {Alebrahim, Azadeh and Heisel, Maritta},
booktitle = {Proceedings of the 19th European Conference on Pattern Languages of Programs},
doi = {10.1145/2721956.2721963},
isbn = {978-1-4503-3416-7},
keywords = { requirements engineering, security patterns,problem frames},
pages = {9:1----9:17},
publisher = {ACM},
series = {EuroPLoP '14},
title = {{Problem-oriented Security Patterns for Requirements Engineering}},
url = {http://doi.acm.org/10.1145/2721956.2721963},
year = {2014}
}
@inproceedings{8049170,
author = {Dekhtyar, A and Fong, V},
booktitle = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2017.26},
keywords = {Bayes methods;formal specification;learning (artificial intelligence);natural language processing;neural nets;pattern classification;systems analysis;text analysis;multilayer neural networks;Word2Vec representation;requirements documents;requirements identification;word count;Word2Vec embeddings;Google TensorFlow package;TensorFlow convolutional neural networks;TensorFlow-guided learning;machine learning techniques;SecReq dataset;NFR dataset;naive Bayes;TF-IDF representation;Convolution;Google;Vocabulary;Feature extraction;Neural networks;Training;machine learning;convolutional neural networks;requirements identification;TensorFlow;Word2Vec},
pages = {484--489},
title = {{RE Data Challenge: Requirements Identification with Word2Vec and TensorFlow}},
year = {2017}
}
@article{Liaskos2011,
abstract = {The priorities that stakeholders associate with requirements may vary from stakeholder to stakeholder and from one situation to the next. Differing priorities, in turn, imply different design decisions for the system to be. While elicitation of requirement priorities is a well-studied activity, modeling and reasoning with prioritization has not enjoyed equal attention. In this paper, we address this problem by extending a state-of-the-art goal modeling notation to support the representation of preference (``nice-to-have'') requirements. In our extension, preference goals are distinguished from mandatory ones. Then, quantitative prioritizations of the former are constructed and used as criteria for evaluating alternative ways to achieve the latter. To generate solutions, an existing preference-based planner is utilized to efficiently search for alternatives that best satisfy a given set of mandatory and preferred requirements. With such a planning tool, analysts can acquire a better understanding of the impact of high-level stakeholder preferences on low-level design decisions.},
author = {Liaskos, Sotirios and McIlraith, Sheila A and Sohrabi, Shirin and Mylopoulos, John},
doi = {10.1007/s00766-011-0129-9},
issn = {1432-010X},
journal = {Requirements Engineering},
month = {aug},
number = {3},
pages = {227},
title = {{Representing and reasoning about preferences in requirements engineering}},
url = {https://doi.org/10.1007/s00766-011-0129-9},
volume = {16},
year = {2011}
}
@article{Shah:2015:RAN:2815021.2815032,
address = {New York, NY, USA},
author = {Shah, Unnati S and Jinwala, Devesh C},
doi = {10.1145/2815021.2815032},
issn = {0163-5948},
journal = {SIGSOFT Softw. Eng. Notes},
keywords = { Natural Language Processing, Requirements Engineering,Ambiguity},
month = {sep},
number = {5},
pages = {1--7},
publisher = {ACM},
title = {{Resolving Ambiguities in Natural Language Software Requirements: A Comprehensive Survey}},
url = {http://doi.acm.org/10.1145/2815021.2815032},
volume = {40},
year = {2015}
}
@inproceedings{8012677,
author = {Glick, M and Rastegarfar, H},
booktitle = {2017 IEEE Photonics Society Summer Topical Meeting Series (SUM)},
doi = {10.1109/PHOSST.2017.8012677},
keywords = {computer centres;electro-optical devices;learning (artificial intelligence);optical communication equipment;resource allocation;software defined networking;telecommunication scheduling;scheduling issues;hybrid electrical-optical data center networks;flexible resource provisioning;programmable resource provisioning;centralized software-defined network control;flow classification;machine learning;Optical switches;Optical fiber networks;Optical packet switching;Image motion analysis;Computer vision;Mice},
month = {jul},
pages = {115--116},
title = {{Scheduling and control in hybrid data centers}},
year = {2017}
}
@inproceedings{8587284,
author = {Buchan, J and Bano, M and Zowghi, D and Volabouth, P},
booktitle = {2018 25th Australasian Software Engineering Conference (ASWEC)},
doi = {10.1109/ASWEC.2018.00013},
keywords = {Bayes methods;feature extraction;learning (artificial intelligence);natural language processing;pattern classification;regression analysis;software development management;support vector machines;text analysis;online reviews;software product evolution;software products;future software releases;potentially unstructured data;noisy data;software release planning decisions;binary classification approach;extracted text;machine learning algorithms;multinomial variants;Bernoulli variants;k-fold cross validation;review sentiment;thousand separate reviews;semiautomated extraction;candidate requirements;unstructured user reviews;noisy online user reviews;machine supported grouping;support release planners;linear support vector machines;Feature extraction;Software;Measurement;Semantics;Support vector machines;Ontologies;Data mining;Software requirements;Feature request;Software product line;Online reviews},
month = {nov},
pages = {31--40},
title = {{Semi-Automated Extraction of New Requirements from Online Reviews for Software Product Evolution}},
year = {2018}
}
@inproceedings{Nurbojatmiko:2018:SIC:3297156.3297200,
address = {New York, NY, USA},
author = {Nurbojatmiko and Budiardjo, Eko K and Wibowo, Wahyu C},
booktitle = {Proceedings of the 2018 2Nd International Conference on Computer Science and Artificial Intelligence},
doi = {10.1145/3297156.3297200},
isbn = {978-1-4503-6606-9},
keywords = { NFR attributes, Non-Functional Requirements (NFR), Requirements Engineering (RE),Functional Requirements (FR)},
pages = {151--157},
publisher = {ACM},
series = {CSAI '18},
title = {{Slr on Identification {\&} Classification of Non-Functional Requirements Attributes, and Its Representation in Functional Requirements}},
url = {http://doi.acm.org/10.1145/3297156.3297200},
year = {2018}
}
@inproceedings{7765522,
author = {Merten, T and Falis, M and H{\"{u}}bner, P and Quirchmayr, T and B{\"{u}}rsner, S and Paech, B},
booktitle = {2016 IEEE 24th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2016.8},
keywords = {learning (artificial intelligence);natural language processing;program debugging;systems analysis;software feature request detection;issue tracking systems;requirements engineering;bug reports;programming tasks;natural language processing;machine learning;natural language data;bag of words;subject-action-object;meta-data;data fields;Software;Computer bugs;Natural languages;Feature extraction;Machine learning algorithms;Prediction algorithms;Training data;Software Feature Request Detection;Mining Software Repositories;Machine Learning;Natural Language Processing},
pages = {166--175},
title = {{Software Feature Request Detection in Issue Tracking Systems}},
year = {2016}
}
@inproceedings{8646010,
author = {Gramajo, M G and Ballejos, L and Ale, M},
booktitle = {2018 IEEE Biennial Congress of Argentina (ARGENCON)},
doi = {10.1109/ARGENCON.2018.8646010},
keywords = {learning (artificial intelligence);software engineering;systems analysis;software products;AA techniques;systematic mapping;software development environments;software requirements engineering;machine learning techniques;Software;Requirements engineering;Machine learning;Supervised learning;Erbium;Proposals;Bibliographies;Aprendizaje Autom{\'{a}}tico;Aprendizaje Supervisado;Ingenier{\'{i}}a de Requerimientos},
month = {jun},
pages = {1--7},
title = {{Software Requirements Engineering through Machine Learning Techniques: A Literature Review}},
year = {2018}
}
@article{MORALESRAMIREZ201994,
abstract = {Online discussions about software applications and services that take place on web-based communication platforms represent an invaluable knowledge source for diverse software engineering tasks, including requirements elicitation. The amount of research work on developing effective tool-supported analysis methods is rapidly increasing, as part of the so called software analytics. Textual messages in App store reviews, tweets, online discussions taking place in mailing lists and user forums, are processed by combining natural language techniques to filter out irrelevant data; text mining and machine learning algorithms to classify messages into different categories, such as bug report and feature request. Our research objective is to exploit a linguistic technique based on speech-acts for the analysis of online discussions with the ultimate goal of discovering requirements-relevant information. In this paper, we present a revised and extended version of the speech-acts based analysis technique, which we previously presented at CAiSE 2017, together with a detailed experimental characterisation of its properties. Datasets used in the experimental evaluation are taken from a widely used open source software project (161120 textual comments), as well as from an industrial project in the home energy management domain. We make them available for experiment replication purposes. On these datasets, our approach is able to successfully classify messages into Feature/Enhancement and Other, with F-measure of 0.81 and 0.84 respectively. We also found evidence that there is an association between types of speech-acts and categories of issues, and that there is correlation between some of the speech-acts and issue priority, thus motivating further research on the exploitation of our speech-acts based analysis technique in semi-automated multi-criteria requirements prioritisation.},
author = {Morales-Ramirez, Itzel and Kifetew, Fitsum Meshesha and Perini, Anna},
doi = {https://doi.org/10.1016/j.is.2018.08.003},
issn = {0306-4379},
journal = {Information Systems},
keywords = { Classification techniques, Online discussions, Sentiment analysis, Speech-acts analysis,Requirements engineering},
pages = {94--112},
title = {{Speech-acts based analysis for requirements discovery from online discussions}},
url = {http://www.sciencedirect.com/science/article/pii/S0306437917306087},
volume = {86},
year = {2019}
}
@inproceedings{Deshpande:2019:SAS:3339663.3339744,
address = {Piscataway, NJ, USA},
author = {Deshpande, Gouri},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings},
doi = {10.1109/ICSE-Companion.2019.00076},
keywords = { machine learning, requirements engineering, requirements inter-dependency management,NLP},
pages = {186--187},
publisher = {IEEE Press},
series = {ICSE '19},
title = {{SReYantra: Automated Software Requirement Inter-dependencies Elicitation, Analysis and Learning}},
url = {https://doi.org/10.1109/ICSE-Companion.2019.00076},
year = {2019}
}
@inproceedings{Abad:2019:SAD:3339505.3339562,
address = {Piscataway, NJ, USA},
author = {Abad, Zahra Shakeri Hossein and Gervasi, Vincenzo and Zowghi, Didar and Far, Behrouz H},
booktitle = {Proceedings of the 41st International Conference on Software Engineering},
doi = {10.1109/ICSE.2019.00057},
keywords = { natural language processing, requirements classification, requirements elicitation, weighted finite state transducers,dynamic language models},
pages = {442--453},
publisher = {IEEE Press},
series = {ICSE '19},
title = {{Supporting Analysts by Dynamic Extraction and Classification of Requirements-related Knowledge}},
url = {https://doi.org/10.1109/ICSE.2019.00057},
year = {2019}
}
@inproceedings{Taj:2019:ADM:3328833.3328837,
address = {New York, NY, USA},
author = {Taj, Soonh and Arain, Qasim and Memon, Imran and Zubedi, Asma},
booktitle = {Proceedings of the 2019 8th International Conference on Software and Information Engineering},
doi = {10.1145/3328833.3328837},
isbn = {978-1-4503-6105-7},
keywords = { Data mining, Functional Requirements and Non-Functional Requirements, Requirement classification, Requirement elicitation,Crowdsourcing},
pages = {42--46},
publisher = {ACM},
series = {ICSIE '19},
title = {{To Apply Data Mining for Classification of Crowd Sourced Software Requirements}},
url = {http://doi.acm.org/10.1145/3328833.3328837},
year = {2019}
}
@inproceedings{8593012,
author = {Alrumaih, H and Mirza, A and Alsalamah, H},
booktitle = {2018 21st Saudi Computer Society National Computer Conference (NCC)},
doi = {10.1109/NCG.2018.8593012},
keywords = {formal specification;formal verification;pattern classification;systems analysis;requirements engineering;software process;software engineering;software systems development;automated software requirements classification;Requirements engineering;Software engineering;Software systems;Machine learning;Stakeholders;software engineering;requirements engineering;requirements classification;artificial intelligence;machine learning},
month = {apr},
pages = {1--6},
title = {{Toward Automated Software Requirements Classification}},
year = {2018}
}
@inproceedings{8258185,
author = {Arruda, D and Madhavji, N H},
booktitle = {2017 IEEE International Conference on Big Data (Big Data)},
doi = {10.1109/BigData.2017.8258185},
keywords = {Big Data;formal specification;end-user Big Data applications;data analytics;process design;requirements engineering artefact model;Big Data software development projects;RE artefact models;BD-REAM;Big Data;Software;Requirements engineering;Data models;Unified modeling language;Software engineering;Stakeholders;Big Data;Requirements Engineering;Artefact Model;Big Data Requirements Engineering Artfect Model},
month = {dec},
pages = {2314--2319},
title = {{Towards a requirements engineering artefact model in the context of big data software development projects: Research in progress}},
year = {2017}
}
@inproceedings{Woodson:2018:TRR:3190645.3190689,
address = {New York, NY, USA},
author = {Woodson, Clinton and Hayes, Jane Huffman and Griffioen, Sarah},
booktitle = {Proceedings of the ACMSE 2018 Conference},
doi = {10.1145/3190645.3190689},
isbn = {978-1-4503-5696-1},
keywords = { information retrieval, machine learning, reproducible research, requirements engineering, statistical analysis, supervised classification learning, text classification,empirical research},
pages = {8:1----8:7},
publisher = {ACM},
series = {ACMSE '18},
title = {{Towards Reproducible Research: Automatic Classification of Empirical Requirements Engineering Papers}},
url = {http://doi.acm.org/10.1145/3190645.3190689},
year = {2018}
}
@inproceedings{8115723,
author = {Mills, C},
booktitle = {2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
doi = {10.1109/ASE.2017.8115723},
keywords = {information retrieval;learning (artificial intelligence);software maintenance;text analysis;automatic classification;traceability links;software projects;source code;project requirements;interaction diagrams;TLR;software task;relevant documents;test coverage;human effort;machine learning classification models;information retrieval;traceability link recovery;Software;Classification algorithms;Semantics;Predictive models;Measurement;Tuning;software traceability;traceability link recovery;machine learning},
month = {oct},
pages = {1018--1021},
title = {{Towards the automatic classification of traceability links}},
year = {2017}
}
@article{Rago2013,
abstract = {Quality-attribute requirements describe constraints on the development and behavior of a software system, and their satisfaction is key for the success of a software project. Detecting and analyzing quality attributes in early development stages provides insights for system design, reduces risks, and ultimately improves the developers' understanding of the system. A common problem, however, is that quality-attribute information tends to be understated in requirements specifications and scattered across several documents. Thus, making the quality attributes first-class citizens becomes usually a time-consuming task for analysts. Recent developments have made it possible to mine concerns semi-automatically from textual documents. Leveraging on these ideas, we present a semi-automated approach to identify latent quality attributes that works in two stages. First, a mining tool extracts early aspects from use cases, and then these aspects are processed to derive candidate quality attributes. This derivation is based on an ontology of quality-attribute scenarios. We have built a prototype tool called QAMiner to implement our approach. The evaluation of this tool in two case studies from the literature has shown interesting results. As main contribution, we argue that our approach can help analysts to skim requirements documents and quickly produce a list of potential quality attributes for the system.},
author = {Rago, Alejandro and Marcos, Claudia and Diaz-Pace, J Andr{\'{e}}s},
doi = {10.1007/s00766-011-0142-z},
issn = {1432-010X},
journal = {Requirements Engineering},
month = {mar},
number = {1},
pages = {67--84},
title = {{Uncovering quality-attribute concerns in use case specifications via early aspect mining}},
url = {https://doi.org/10.1007/s00766-011-0142-z},
volume = {18},
year = {2013}
}
@article{Jha2018,
abstract = {Text mining techniques have been recently employed to classify and summarize user reviews on mobile application stores. However, due to the inherently diverse and unstructured nature of user-generated online textual data, text-based review mining techniques often produce excessively complicated models that are prone to overfitting. In this paper, we propose a novel approach, based on frame semantics, for app review mining. Semantic frames help to generalize from raw text (individual words) to more abstract scenarios (contexts). This lower-dimensional representation of text is expected to enhance the predictive capabilities of review mining techniques and reduce the chances of overfitting. Specifically, our analysis in this paper is two-fold. First, we investigate the performance of semantic frames in classifying informative user reviews into various categories of actionable software maintenance requests. Second, we propose and evaluate the performance of multiple summarization algorithms in generating concise and representative summaries of informative reviews. Three different datasets of app store reviews, sampled from a broad range of application domains, are used to conduct our experimental analysis. The results show that semantic frames can enable an efficient and accurate review classification process. However, in review summarization tasks, our results show that text-based summarization generates more comprehensive summaries than frame-based summarization. Finally, we introduces MARC 2.0, a review classification and summarization suite that implements the algorithms investigated in our analysis.},
author = {Jha, Nishant and Mahmoud, Anas},
doi = {10.1007/s10664-018-9605-x},
issn = {1573-7616},
journal = {Empirical Software Engineering},
month = {dec},
number = {6},
pages = {3734--3767},
title = {{Using frame semantics for classifying and summarizing application store reviews}},
url = {https://doi.org/10.1007/s10664-018-9605-x},
volume = {23},
year = {2018}
}
@article{Rago2018,
abstract = {Engineering activities often produce considerable documentation as a by-product of the development process. Due to their complexity, technical analysts can benefit from text processing techniques able to identify concepts of interest and analyze deficiencies of the documents in an automated fashion. In practice, text sentences from the documentation are usually transformed to a vector space model, which is suitable for traditional machine learning classifiers. However, such transformations suffer from problems of synonyms and ambiguity that cause classification mistakes. For alleviating these problems, there has been a growing interest in the semantic enrichment of text. Unfortunately, using general-purpose thesaurus and encyclopedias to enrich technical documents belonging to a given domain (e.g. requirements engineering) often introduces noise and does not improve classification. In this work, we aim at boosting text classification by exploiting information about semantic roles. We have explored this approach when building a multi-label classifier for identifying special concepts, called domain actions, in textual software requirements. After evaluating various combinations of semantic roles and text classification algorithms, we found that this kind of semantically-enriched data leads to improvements of up to 18{\%} in both precision and recall, when compared to non-enriched data. Our enrichment strategy based on semantic roles also allowed classifiers to reach acceptable accuracy levels with small training sets. Moreover, semantic roles outperformed Wikipedia- and WordNET-based enrichments, which failed to boost requirements classification with several techniques. These results drove the development of two requirements tools, which we successfully applied in the processing of textual use cases.},
author = {Rago, Alejandro and Marcos, Claudia and Diaz-Pace, J Andres},
doi = {10.1007/s10579-017-9406-7},
issn = {1574-0218},
journal = {Language Resources and Evaluation},
month = {sep},
number = {3},
pages = {801--837},
title = {{Using semantic roles to improve text classification in the requirements domain}},
url = {https://doi.org/10.1007/s10579-017-9406-7},
volume = {52},
year = {2018}
}
@inproceedings{6894850,
author = {Hayes, J H and Li, W and Rahimi, M},
booktitle = {2014 IEEE 1st International Workshop on Artificial Intelligence for Requirements Engineering (AIRE)},
doi = {10.1109/AIRE.2014.6894850},
keywords = {decision trees;formal specification;learning (artificial intelligence);pattern classification;TraceLab Weka component;Weka classification trees;requirements research tools;one off solutions;requirements engineering problems;Weka machine learning software suite;Classification tree analysis;Classification algorithms;Machine learning algorithms;Educational institutions;Software;Supervised learning;Artificial intelligence;machine learning;requirements engineering;classification;decision trees;TraceLab;Weka},
month = {aug},
pages = {9--12},
title = {{Weka meets TraceLab: Toward convenient classification: Machine learning for requirements engineering problems: A position paper}},
year = {2014}
}
@inproceedings{8049172,
author = {Abad, Z S H and Karras, O and Ghazi, P and Glinz, M and Ruhe, G and Schneider, K},
booktitle = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
doi = {10.1109/RE.2017.36},
keywords = {Bayes methods;formal specification;learning (artificial intelligence);natural languages;pattern classification;text analysis;NFR;preprocessing requirements;standardizes;classification algorithms;requirements engineering;natural language;machine learning;requirements classification;nonfunctional requirements;OpenScience tera-PROMISE repository;Latent Dirichlet Allocation;Biterm Topic Modeling;Naive Bayes;Feature extraction;Natural languages;Tagging;Requirements engineering;Machine learning algorithms;Speech;Functional and Non-Functional Requirements;Classification;Topic Modeling;Clustering;Naive Bayes},
pages = {496--501},
title = {{What Works Better? A Study of Classifying Requirements}},
year = {2017}
}
