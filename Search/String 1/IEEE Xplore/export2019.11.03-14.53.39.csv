"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication_Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License","Online Date",Issue Date,"Meeting Date","Publisher",Document Identifier
"Towards Emotionally Aware AI Smart Classroom: Current Issues and Directions for Engineering and Education","Y. Kim; T. Soyata; R. F. Behnagh","Department of Electrical and Computer Engineering, State University of New York at Albany, Albany, NY, USA; Department of Electrical and Computer Engineering, State University of New York at Albany, Albany, NY, USA; Department of Educational Theory and Practice, State University of New York at Albany, Albany, NY, USA","IEEE Access","","2018","6","","5308","5331","Future smart classrooms that we envision will significantly enhance learning experience and seamless communication among students and teachers using real-time sensing and machine intelligence. Existing developments in engineering have brought the state-of-the-art to an inflection point, where they can be utilized as components of a smart classroom. In this paper, we propose a smart classroom system that consists of these components. Our proposed system is capable of making real-time suggestions to an in-class presenter to improve the quality and memorability of their presentation by allowing the presenter to make real-time adjustments/corrections to their non-verbal behavior, such as hand gestures, facial expressions, and body language. We base our suggested system components on existing research in affect sensing, deep learning-based emotion recognition, and real-time mobile-cloud computing. We provide a comprehensive study of these technologies and determine the computational requirements of a system that incorporates these technologies. Based on these requirements, we provide a feasibility study of the system. Although the state-of-the-art research in most of the components we propose in our system are advanced enough to realize the system, the main challenge lies in: 1) the integration of these technologies into a holistic system design; 2) their algorithmic adaptation to allow real-time execution; and 3) quantification of valid educational variables for use in algorithms. In this paper, we discuss current issues and provide future directions in engineering and education disciplines to deploy the proposed system.","","","10.1109/ACCESS.2018.2791861","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8253436","Educational technology;emotion recognition;smart classroom;deep learning;real-time computing;mobile-cloud computing;meta-cognition","Real-time systems;Education;Engines;Machine learning;System analysis and design;Haptic interfaces;Visualization","cloud computing;computer aided instruction;distance learning;emotion recognition;engineering education;face recognition;gesture recognition;human computer interaction;learning (artificial intelligence);mobile computing","learning experience;real-time sensing;real-time suggestions;in-class presenter;real-time adjustments/corrections;real-time execution;system components;emotionally aware AI smart classroom;seamless communication;machine intelligence;affect sensing;deep learning-based emotion recognition;real-time mobile-cloud computing;computational requirements;engineering discipline;education discipline","","9","","185","","","","","IEEE","IEEE Journals"
"Automatic Detection of Ambiguous Software Requirements: An Insight","M. Q. Riaz; W. H. Butt; S. Rehman","Department of Computer Engineering, College of E&ME, National University of Science & Technology (NUST), Islamabad, Pakistan; Department of Computer Engineering, College of E&ME, National University of Science & Technology (NUST), Islamabad, Pakistan; Department of Computer Engineering, College of E&ME, National University of Science & Technology (NUST), Islamabad, Pakistan","2019 5th International Conference on Information Management (ICIM)","","2019","","","1","6","Requirements Engineering is one of the most important phases of the software development lifecycle. The success of the whole software project depends upon the quality of the requirements. But as we know that mostly the software requirements are stated and documented in the natural language. The requirements written in natural language can be ambiguous and inconsistent. These ambiguities and inconsistencies can lead to misinterpretations and wrong implementations in design and development phase. To address these issues a number of approaches, tools and techniques have been proposed for the automatic detection of natural language ambiguities form software requirement documents. However, to the best of our knowledge, there is very little work done to compare and analyze the differences between these tools and techniques. In this paper, we presented a state of art survey of the currently available tools and techniques for the automatic detection of natural language ambiguities from software requirements. We also focused on figuring out the popularity of different tools and techniques on the basis of citations. This research will help the practitioners and researchers to get the latest insights in the above-mentioned context.","","","10.1109/INFOMAN.2019.8714682","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8714682","natural language requirement;requirement engineering;ambiguity;natural language ambiguity;ambiguous software requirements;natural language processing","Software;Tools;Natural language processing;Documentation;Knowledge based systems;Machine learning","formal specification;natural language processing;software quality;systems analysis","development phase;automatic detection;natural language ambiguities;software requirement documents;ambiguous software requirements;Requirements Engineering;software development lifecycle;software project","","","","46","","","","","IEEE","IEEE Conferences"
"Which One to Read? Factors Influencing the Usefulness of Online Reviews for RE","E. B. Charrada","Dept. of Inf., Univ. of Zurich, Zurich, Switzerland","2016 IEEE 24th International Requirements Engineering Conference Workshops (REW)","","2016","","","46","52","Reviews for software products contain much information about the users' requirements and preferences, which can be very useful to the requirements engineer. However, taking advantage of this information is not easy due to the large and overwhelming number of reviews that is posted in various channels. Machine learning and opinion mining techniques have therefore been used to process the reviews automatically and to generate summaries of the data to the requirements engineer. However, one of the important challenges for these techniques lies in how to automatically assess the relevance of the reviews for the requirements engineer. So far, most techniques use intuition-based criteria for this task. In this work, we collect and present a list of factors that were found to impact the helpfulness of product reviews for customers. We then discuss to what extent these factors are likely to impact the usefulness of reviews for requirements engineering tasks. The factors can be used to support the automated identification of relevant reviews.","","","10.1109/REW.2016.022","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7815605","","Requirements engineering;Software;Conferences;Data mining;Extremities;Quality assessment;Product design","data mining;formal specification;formal verification;information analysis;learning (artificial intelligence);software reviews","online reviews;RE;software products;machine learning;opinion mining techniques;intuition-based criteria;requirements engineering tasks;automated identification","","2","","47","","","","","IEEE","IEEE Conferences"
"What do Support Analysts Know About Their Customers? On the Study and Prediction of Support Ticket Escalations in Large Software Organizations","L. Montgomery; D. Damian","NA; NA","2017 IEEE 25th International Requirements Engineering Conference (RE)","","2017","","","362","371","Understanding and keeping the customer happy is a central tenet of requirements engineering. Strategies to gather, analyze, and negotiate requirements are complemented by efforts to manage customer input after products have been deployed. For the latter, support tickets are key in allowing customers to submit their issues, bug reports, and feature requests. Whenever insufficient attention is given to support issues, however, their escalation to management is time-consuming and expensive, especially for large organizations managing hundreds of customers and thousands of support tickets. Our work provides a step towards simplifying the job of support analysts and managers, particularly in predicting the risk of escalating support tickets. In a field study at our large industrial partner, IBM, we used a design science methodology to characterize the support process and data available to IBM analysts in managing escalations. Through iterative cycles of design and evaluation, we translated our understanding of support analysts' expert knowledge of their customers into features of a support ticket model to be implemented into a Machine Learning model to predict support ticket escalations. We trained and evaluated our Machine Learning model on over 2.5 million support tickets and 10,000 escalations, obtaining a recall of 79.9% and an 80.8% reduction in the workload for support analysts looking to identify support tickets at risk of escalation. Further on-site evaluations, through a prototype tool we developed to implement our Machine Learning techniques in practice, showed more efficient weekly support-ticket-management meetings. The features we developed in the Support Ticket Model are designed to serve as a starting place for organizations interested in implementing our model to predict support ticket escalations, and for future researchers to build on to advance research in escalation prediction.","","","10.1109/RE.2017.61","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8049142","Customer relationship management;machine learning;escalation prediction;customer support ticket","Organizations;Analytical models;Software;Predictive models;Iron;Customer relationship management;Computer bugs","customer services;learning (artificial intelligence);software development management;software maintenance","Machine Learning model;support ticket model;support ticket escalations;customer input;managing escalations;weekly support-ticket-management meetings;design science methodology;escalation risk;machine learning techniques;design cycle;escalation cycle","","5","","25","","","","","IEEE","IEEE Conferences"
"Experiment on automatic functional requirements analysis with the EFRF's semantic cases","Y. Wang; J. Zhang","School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China; School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China","2016 International Conference on Progress in Informatics and Computing (PIC)","","2016","","","636","642","Software requirements analysis is crucial for any software project and it is the basis of requirements reuse within Software Product Line engineering. Software requirements specifications are usually expressed in natural language, which are informal, imprecise and ambiguous, thus analyzing them automatically is a challenging task. Although methods towards automatic analysis of software requirements have been studied before, many of them have limitations and effective researches in this area are still lacking. Therefore, in this paper a new approach was proposed to automatically extract structured information of functional requirements from Software Requirements Specifications in natural language. The methods of machine learning, natural language processing and semantic analysis were employed and combined in this approach. With a 10-fold cross validation setting, the method was evaluated on a manually annotated corpus. The experiments show that this approach achieves a good performance. Moreover, it was found that the model trained on the requirements dataset of the E-commerce systems, can be used to extract semantic information from the requirements of auto-maker systems. The cross-domain extraction results show that the method of this paper is domain independent and robust to some extent.","","","10.1109/PIC.2016.7949577","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7949577","requirements engineering;functional requirements extraction;EFRF;semantic analysis","Software;Semantics;Tagging;Natural languages;Feature extraction;Stakeholders;Labeling","electronic commerce;formal specification;information retrieval;learning (artificial intelligence);natural language processing;software management;software product lines;text analysis","cross-domain extraction;auto-maker systems;semantic information extraction;E-commerce systems;manually annotated corpus;10-fold cross validation;semantic analysis;natural language processing;machine learning;automatic structured information extraction;automatic software requirements analysis;software requirements specifications;requirements reuse;software product line engineering;software project;software requirements analysis;EFRF;automatic functional requirements analysis","","1","","22","","","","","IEEE","IEEE Conferences"
"Extending Nocuous Ambiguity Analysis for Anaphora in Natural Language Requirements","H. Yang; A. de Roeck; V. Gervasi; A. Willis; B. Nuseibeh","Dept. of Comput., Open Univ., Milton Keynes, UK; Dept. of Comput., Open Univ., Milton Keynes, UK; Dept. of Comput. Sci., Univ. of Pisa, Pisa, Italy; Dept. of Comput., Open Univ., Milton Keynes, UK; Dept. of Comput., Open Univ., Milton Keynes, UK","2010 18th IEEE International Requirements Engineering Conference","","2010","","","25","34","This paper presents an approach to automatically identify potentially nocuous ambiguities, which occur when text is interpreted differently by different readers of requirements written in natural language. We extract a set of anaphora ambiguities from a range of requirements documents, and collect multiple human judgments on their interpretations. The judgment distribution is used to determine if an ambiguity is nocuous or innocuous. We investigate a number of antecedent preference heuristics that we use to explore aspects of anaphora which may lead a reader to favour a particular interpretation. Using machine learning techniques, we build an automated tool to predict the antecedent preference of noun phrase candidates, which in turn is used to identify nocuous ambiguity. We report on a series of experiments that we conducted to evaluate the performance of our automated system. The results show that the system achieves high recall with a consistent improvement on baseline precision subject to some ambiguity tolerance levels, allowing us to explore and highlight realistic and potentially problematic ambiguities in actual requirements documents.",";","","10.1109/RE.2010.14","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=5636921","nocuous ambiguity;NL requirements;anaphora ambiguity;antecedent preference heuristics;machine learning","Syntactics;Semantics;Humans;Prototypes;Context;Manuals;Pragmatics","formal specification;formal verification;learning (artificial intelligence);natural languages;systems analysis","nocuous ambiguity analysis;anaphora;natural language requirement;requirements document;human judgment;judgment distribution;antecedent preference heuristics;machine learning technique;noun phrase;automated system;baseline precision","","18","","25","","","","","IEEE","IEEE Conferences"
"From User Demand to Software Service: Using Machine Learning to Automate the Requirements Specification Process","L. van Rooijen; F. S. Bäumer; M. C. Platenius; M. Geierhos; H. Hamann; G. Engels","Dept. of Comput. Sci., Paderborn Univ., Paderborn, Germany; Heinz Nixdorf Inst., Paderborn Univ., Paderborn, Germany; Dept. of Comput. Sci., Paderborn Univ., Paderborn, Germany; Heinz Nixdorf Inst., Paderborn Univ., Paderborn, Germany; Inst. of Comput. Eng., Univ. of Lubeck, Lubeck, Germany; Dept. of Comput. Sci., Paderborn Univ., Paderborn, Germany","2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)","","2017","","","379","385","Bridging the gap between informal, imprecise, and vague user requirements descriptions and precise formalized specifications is the main task of requirements engineering. Techniques such as interviews or story telling are used when requirements engineers try to identify a user's needs. The requirements specification process is typically done in a dialogue between users, domain experts, and requirements engineers. In our research, we aim at automating the specification of requirements. The idea is to distinguish between untrained users and trained users, and to exploit domain knowledge learned from previous runs of our system. We let untrained users provide unstructured natural language descriptions, while we allow trained users to provide examples of behavioral descriptions. In both cases, our goal is to synthesize formal requirements models similar to statecharts. From requirements specification processes with trained users, behavioral ontologies are learned which are later used to support the requirements specification process for untrained users. Our research method is original in combining natural language processing and search-based techniques for the synthesis of requirements specifications. Our work is embedded in a larger project that aims at automating the whole software development and deployment process in envisioned future software service markets.","","","10.1109/REW.2017.26","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8054881","","Software;Unified modeling language;Requirements engineering;Ontologies;Search problems;Natural languages","formal specification;learning (artificial intelligence);natural language processing;ontologies (artificial intelligence);software development management;systems analysis","untrained users;trained users;formal requirements models;requirements engineering;unstructured natural language description;behavioral descriptions;behavioral ontologies;search-based technique;software deployment process automation;software development process automation;software service markets","","1","","22","","","","","IEEE","IEEE Conferences"
"Ambiguous Software Requirement Specification Detection: An Automated Approach","M. H. Osman; M. F. Zaharin","NA; NA","2018 IEEE/ACM 5th International Workshop on Requirements Engineering and Testing (RET)","","2018","","","33","40","Software requirement specification (SRS) document is the most crucial document in software development process. All subsequent steps in software development are influenced by this document. However, issues in requirement, such as ambiguity or incomplete specification may lead to misinterpretation of requirements which consequently, influence the testing activities and higher the risk of time and cost overrun of the project. Finding defects in the initial development phase is crucial since the defect that found late is more expensive than if it was found early. This study describes an automated approach for detecting ambiguous software requirement specification. To this end, we propose the combination of text mining and machine learning. Since the dataset is derived from Malaysian industrial SRS documents, this study only focuses on the Malaysian context. We used text mining for feature extraction and for preparing the training set. Based on this training set, the method `learns' to detect the ambiguous requirement specification. In this paper, we study a set of nine (9) classification algorithms from the machine learning community and evaluate which algorithm performs best to detect the ambiguous software requirement specification. Based on the experiment's result, we develop a working prototype which later is used for our initial validation of our approach. The initial validation shows that the result produced by the classification model is reasonably acceptable. Even though this study is an experimental benchmark, we optimist that this approach may contributes to enhance the quality of SRS.","","","","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8444122","Software Engineering;Requirement Engineering;Machine Learning;Text Mining","Conferences;Requirements engineering;Testing","data mining;feature extraction;formal specification;learning (artificial intelligence);pattern classification;project management;software development management;software engineering;software quality;text analysis","automated approach;text mining;Malaysian industrial SRS documents;training set;ambiguous software requirement specification detection;software requirement specification document;crucial document;software development process;initial development phase;machine learning;feature extraction;classification algorithms;working prototype;classification model","","","","29","","","","","IEEE","IEEE Conferences"
"Towards a requirements engineering artefact model in the context of big data software development projects: Research in progress","D. Arruda; N. H. Madhavji","Department of Computer Science, University of Western Ontario, London, Canada; Department of Computer Science, University of Western Ontario, London, Canada","2017 IEEE International Conference on Big Data (Big Data)","","2017","","","2314","2319","There is ample literature that suggests that the field of Big Data is growing rapidly. Also, there is emerging literature on the need to create end-user Big Data applications, as distinct from “data analytics” that typically employs machine learning algorithms to find value in large datasets for the stakeholder. A solid foundation for creating sound applications is a thorough understanding of domain and artefact models that embody artefact types and activities involved in a software project. This paper focuses on the Requirements Engineering (RE) aspect of a Big Data software project. Currently, there are no known RE artefact models to support RE process design and project understanding. To fill this void, this paper proposes a RE artefact model for Big Data end-user applications (BD-REAM). The paper also describes a method for creating the artefact model, including the basic elements and inter-relationships involved in the model.","","","10.1109/BigData.2017.8258185","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8258185","Big Data;Requirements Engineering;Artefact Model;Big Data Requirements Engineering Artfect Model","Big Data;Software;Requirements engineering;Data models;Unified modeling language;Software engineering;Stakeholders","Big Data;formal specification","end-user Big Data applications;data analytics;process design;requirements engineering artefact model;Big Data software development projects;RE artefact models;BD-REAM","","","","36","","","","","IEEE","IEEE Conferences"
"Goals at risk? Machine learning at support of early assessment","P. Avesani; A. Perini; A. Siena; A. Susi","Fondazione Bruno Kessler, Trento-Povo, I-38123 Italy; Fondazione Bruno Kessler, Trento-Povo, I-38123 Italy; Fondazione Bruno Kessler, Trento-Povo, I-38123 Italy; Fondazione Bruno Kessler, Trento-Povo, I-38123 Italy","2015 IEEE 23rd International Requirements Engineering Conference (RE)","","2015","","","252","255","A relevant activity in the requirements engineering process consists in the identification, assessment and management of potential risks, which can prevent the system-to-be from meeting stakeholder needs. However, risk analysis techniques are often time- and resource- consuming activities, which may introduce in the requirements engineering process a significant overhead. To overcome this problem, we aim at supporting risk management activity in a semi-automated way, merging the capability to exploit existing risk-related information potentially present in a given organisation, with an automated ranking of the goals with respect to the level of risk the decision-maker estimates for them. In particular, this paper proposes an approach to address the general problem of risk decision-making, which combines knowledge about risks assessment techniques and Machine Learning to enable an active intervention of human evaluators in the decision process, learning from their feedback and integrating it with the organisational knowledge. The long term objective is that of improving the capacity of an organisation to be aware and to manage risks, by introducing new techniques in the field of risk management that are able to interactively and continuously extract useful knowledge from the organisation domain and from the decision-maker expertise.",";","","10.1109/RE.2015.7320432","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7320432","","Risk management;Decision making;Requirements engineering;Approximation methods;Open source software;Yttrium","decision making;formal specification;knowledge acquisition;learning (artificial intelligence)","machine learning;requirements engineering process;potential risk identification;potential risk assessment;potential risk management;risk analysis techniques;risk-related information;automated ranking;decision-maker;risks assessment techniques;human evaluators;decision process;organisational knowledge;knowledge extraction","","1","","9","","","","","IEEE","IEEE Conferences"
"Early failure prediction in feature request management systems","C. Fitzgerald; E. Letier; A. Finkelstein","Dept. of Computer Science, University College London, London, United Kingdom; Dept. of Computer Science, University College London, London, United Kingdom; Dept. of Computer Science, University College London, London, United Kingdom","2011 IEEE 19th International Requirements Engineering Conference","","2011","","","229","238","Online feature request management systems are popular tools for gathering stakeholder requirements during system evolution. Deciding which feature requests require attention and how much upfront analysis to perform on them is an important problem in this context: too little upfront analysis may result in inadequate functionalities being developed, costly changes, and wasted development effort; too much upfront analysis is a waste of time and resources. Early predictions about which feature requests are most likely to fail due to insufficient or inadequate upfront analysis could facilitate such decisions. Our objective is to study whether it is possible to make such predictions automatically from the characteristics of the online discussions on feature requests. The paper presents a tool-implemented framework that automatically constructs failure prediction models using machine-learning classification algorithms and compares the performance of the different techniques for the Firefox and Netbeans projects. The comparison relies on a cost-benefit model for assessing the value of additional upfront analysis. In this model, the value of additional upfront analysis depends on its probability of success in preventing failures and on the relative cost of the failures it prevents compared to its own cost. We show that for reasonable estimations of these two parameters automated prediction models provide more value than a set of baselines for some failure types and projects. This suggests that automated failure prediction during online requirements elicitation may be a promising approach for guiding requirements engineering efforts in online settings.",";;","","10.1109/RE.2011.6051658","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=6051658","Early failure prediction;Cost-benefit of requirements engineering;Feature requests management systems;Global software development;Open source","Predictive models;Fires;Analytical models;Educational institutions;Feature extraction;Mathematical model","formal verification;learning (artificial intelligence);pattern classification","early failure prediction;online feature request management systems;machine-learning classification algorithms;cost-benefit model;requirements engineering","","8","","23","","","","","IEEE","IEEE Conferences"
"Which Feature is Unusable? Detecting Usability and User Experience Issues from User Reviews","E. Bakiu; E. Guzman","Tech. Univ. Munchen, Munich, Germany; Univ. of Zurich, Zurich, Switzerland","2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)","","2017","","","182","187","Usability and user experience (UUX) strongly affect software quality and success. User reviews allow software users to report UUX issues. However, this information can be difficult to access due to the varying quality of the reviews, its large numbers and unstructured nature. In this work we propose an approach to automatically detect the UUX strengths and issues of software features according to user reviews. We use a collocation algorithm for extracting the features, lexical sentiment analysis for uncovering users' satisfaction about a particular feature and machine learning for detecting the specific UUX issues affecting the software application. Additionally, we present two visualizations of the results. An initial evaluation of the approach against human judgement obtained mixed results.","","","10.1109/REW.2017.76","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8054850","user feedback;software evolution;text mining;user experience;usability","Feature extraction;Usability;Data mining;Visualization;Software algorithms;Sentiment analysis","feature extraction;human factors;learning (artificial intelligence);sentiment analysis;software quality","software users;software features;user reviews;software application;user experience issues;software quality;Usability and user experience;UUX;collocation algorithm;feature extraction;lexical sentiment analysis;machine learning","","1","","37","","","","","IEEE","IEEE Conferences"
"Open innovation in software requirements engineering: A mapping study","H. Yin; D. Pfahl","Institute of Computer Science, University of Tartu, J. Liivi 2, Tartu 50409, Estonia; Institute of Computer Science, University of Tartu, J. Liivi 2, Tartu 50409, Estonia","2017 8th IEEE International Conference on Software Engineering and Service Science (ICSESS)","","2017","","","5","10","Background: Since 2003, when the concept of open innovation (OI) was introduced, OI has been applied in many industrial fields. Previous research indicates that the use of OI in computer science is less diverse than in other fields. Especially, the role of OI in software requirements engineering (RE) seems to be little explored. Goals: This study aimed to summarize the body of knowledge about the use of OI in the field of RE. More specifically, we analyzed what uses of OI in the context of RE have been reported and how OI has contributed to individual steps of the RE process. Method: We conduct a mapping study on the literature provided in four scientific databases (ISI Web of Science, IEEE Xplore, ACM Digital Library, and Science Direct). Results: We identified 20 relevant papers. We found: 1) 20 primary studies from the period 2003-2016 report on results about applying OI in RE. 2) Half of the studies report on the application of OI on RE as a whole. 3) Only one paper each is related to requirement prioritization and validation. 4) None of the primary studies presents a proprietary tool support for OI in RE. Only one study presents a method for automatic requirements extraction in OSS projects which can be implemented using standard machine learning tools. Conclusions: Acknowledging the lack of published research on the use of OI strategies in specific RE activities, i.e., prioritization and validation, as well as the lack of reported tool support, we see new opportunities for research on automated and thus non-intrusive and low-cost methods for applying OI strategies in RE.","","","10.1109/ICSESS.2017.8342852","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8342852","Open Innovation;Requirement Engineering;Literature Review","Technological innovation;Software;Databases;Requirements engineering;Stakeholders;Data mining;Computer science","innovation management;public domain software;software engineering","open innovation;software requirements engineering;mapping study;OI strategies;OSS projects","","","","37","","","","","IEEE","IEEE Conferences"
"Hidden in plain sight: Automatically identifying security requirements from natural language artifacts","M. Riaz; J. King; J. Slankas; L. Williams","Department of Computer Science, North Carolina State University, Raleigh, USA; Department of Computer Science, North Carolina State University, Raleigh, USA; Department of Computer Science, North Carolina State University, Raleigh, USA; Department of Computer Science, North Carolina State University, Raleigh, USA","2014 IEEE 22nd International Requirements Engineering Conference (RE)","","2014","","","183","192","Natural language artifacts, such as requirements specifications, often explicitly state the security requirements for software systems. However, these artifacts may also imply additional security requirements that developers may overlook but should consider to strengthen the overall security of the system. The goal of this research is to aid requirements engineers in producing a more comprehensive and classified set of security requirements by (1) automatically identifying security-relevant sentences in natural language requirements artifacts, and (2) providing context-specific security requirements templates to help translate the security-relevant sentences into functional security requirements. Using machine learning techniques, we have developed a tool-assisted process that takes as input a set of natural language artifacts. Our process automatically identifies security-relevant sentences in the artifacts and classifies them according to the security objectives, either explicitly stated or implied by the sentences. We classified 10,963 sentences in six different documents from healthcare domain and extracted corresponding security objectives. Our manual analysis showed that 46% of the sentences were security-relevant. Of these, 28% explicitly mention security while 72% of the sentences are functional requirements with security implications. Using our tool, we correctly predict and classify 82% of the security objectives for all the sentences (precision). We identify 79% of all security objectives implied by the sentences within the documents (recall). Based on our analysis, we develop context-specific templates that can be instantiated into a set of functional security requirements by filling in key information from security-relevant sentences.",";","","10.1109/RE.2014.6912260","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=6912260","Security;requirements;objectives;templates;access control;auditing;text classification;constraints;natural language parsing","Security;Natural languages;Object recognition;Software systems;Availability;Medical services;Text categorization","formal specification;learning (artificial intelligence);natural language processing;security of data","natural language artifacts;requirements specifications;software systems;requirements engineer;security-relevant sentences;natural language requirements artifacts;context-specific security requirements templates;functional security requirements;machine learning techniques;tool-assisted process;security objectives;healthcare domain;functional requirements;context-specific templates","","16","","40","","","","","IEEE","IEEE Conferences"
"SIMISS: A Model-Based Searching Strategy for Inventory Management Systems","Y. T. Demey; M. Wolff","Department of Requirements Engineering and Solution Design (Search and Knowledge Management IM2.8.3.3), European Patent Office, EE Rijswijk, The Netherlands; European Space Agency, ESA/ESTEC/TEC-SWM, Noordwijk, AZ, The Netherlands","IEEE Internet of Things Journal","","2017","4","1","172","182","Inventory management is critical in human space flight operations. Currently, we use the inventory management system (IMS) in keeping track of items on the International Space Station (ISS). One challenge is to discover lost or wrongly placed items when IMS fails to discover them due to human factors. In this paper, we will illustrate a model-based searching strategy called semantic inventory management for ISS (SIMISS), with which possible locations of lost items will be calculated based on contextual features in three dimensions: (1) spatial; (2) temporal; and (3) human. It contains ontologies, databases, machine learning algorithms, and ubiquitous client applications. We have implemented and tested SIMISS with the sample data from IMS, operation data files and onboard short term plan experiments have been carried out in a set of simulation scenarios.",";","","10.1109/JIOT.2016.2638023","ESA under the Research Fellowship Program (RFP); ","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7778999","Big data analysis;fact-based modeling (FBM);Internet of Things (IoT);radio frequency identification (RFID)","Ontologies;Inventory management;Context;Machine learning algorithms;Internet of Things;Semantics;Analytical models","aerospace computing;database management systems;inventory management;learning (artificial intelligence);ontologies (artificial intelligence);ubiquitous computing","model-based searching strategy;human space flight operations;IMS;International Space Station;human factors;semantic inventory management-for-ISS;contextual features;spatial dimension;temporal dimension;human dimension;ontologies;database mangement;machine learning algorithms;ubiquitous client applications;SIMISS;operation data files","","","","51","","","","","IEEE","IEEE Journals"
"Probing for Requirements Knowledge to Stimulate Architectural Thinking","P. R. Anish; B. Balasubramaniam; A. Sainani; J. Cleland-Huang; M. Daneva; R. J. Wieringa; S. Ghaisas","TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India; TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India; TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India; Syst. & Requirements Eng. Center, DePaul Univ., Chicago, IL, USA; Univ. of Twente, Enschede, Netherlands; Univ. of Twente, Enschede, Netherlands; TATA Res. Dev. & Design Centre, TATA Consultancy Services Ltd., Pune, India","2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)","","2016","","","843","854","Software requirements specifications (SRSs) often lack the detail needed to make informed architectural decisions. Architects therefore either make assumptions, which can lead to incorrect decisions, or conduct additional stakeholder interviews, resulting in potential project delays. We previously observed that software architects ask Probing Questions (PQs) to gather information crucial to architectural decision-making. Our goal is to equip Business Analysts with appropriate PQs so that they can ask these questions themselves. We report a new study with over 40 experienced architects to identify reusable PQs for five areas of functionality and organize them into structured flows. These PQflows can be used by Business Analysts to elicit and specify architecturally relevant information. Additionally, we leverage machine learning techniques to determine when a PQ-flow is appropriate for use in a project, and to annotate individual PQs with relevant information extracted from the existing SRS. We trained and evaluated our approach on over 8,000 individual requirements from 114 requirements specifications and also conducted a pilot study to validate its usefulness.","","","10.1145/2884781.2884801","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7886961","Architecturally significant requirements;automated requirement classification;functional requirements;requirements knowledge;Probing Questions (PQs);PQ-flows","Interviews;Barium;Software;Stakeholders;Batch production systems;Requirements engineering","formal specification;learning (artificial intelligence);software architecture","requirements knowledge;architecturally significant requirements;probing questions;PQ-flow;machine learning techniques;software requirements specifications;SRS","","2","","52","","","","","IEEE","IEEE Conferences"
"Let’s Hear it from RETTA: A Requirements Elicitation Tool for TrAffic Management Systems","M. Noaeen; Z. S. H. Abad; B. H. Far","Dept. of Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada; Dept. of Comput. Sci., Univ. of Calgary, Calgary, AB, Canada; Dept. of Electr. & Comput. Eng., Univ. of Calgary, Calgary, AB, Canada","2017 IEEE 25th International Requirements Engineering Conference (RE)","","2017","","","450","451","The area of Traffic Management (TM) is characterized by uncertainty, complexity, and imprecision. The complexity of software systems in the TM domain which contributes to a more challenging Requirements Engineering (RE) job mainly stems from the diversity of stakeholders and complexity of requirements elicitation in this domain. This work brings an interactive solution for exploring functional and non-functional requirements of software-reliant systems in the area of traffic management. We prototyped the RETTA tool which leverages the wisdom of the crowd and combines it with machine learning approaches such as Natural Language Processing and Naïve Bayes to help with the requirements elicitation and classification task in the TM domain. This bridges the gap among stakeholders from both areas of software development and transportation engineering. The RETTA prototype is mainly designed for requirements engineers and software developers in the area of TM and can be used on Android-based devices.","","","10.1109/RE.2017.78","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8049156","Requirements Engineering;Transportation Management;Tool Development;Traffic Signal Timing","Tools;Transportation;Complexity theory;Data analysis;Prototypes;Computational modeling;Requirements engineering","Android (operating system);Bayes methods;formal specification;graphical user interfaces;learning (artificial intelligence);natural language processing;pattern classification;systems analysis;traffic engineering computing","TM domain;software development;transportation engineering;software systems;nonfunctional requirements;software-reliant systems;RETTA tool;machine learning approaches;Natural Language Processing;requirements engineering;requirements elicitation tool-for-traffic management systems;functional requirements;naïve Bayes method;Android-based devices","","4","","7","","","","","IEEE","IEEE Conferences"
"Automatic Multi-class Non-Functional Software Requirements Classification Using Neural Networks","C. Baker; L. Deng; S. Chakraborty; J. Dehlinger","Towson University; Towson University; Towson University; Towson University","2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)","","2019","2","","610","615","Advances in machine learning (ML) algorithms, graphics processing units, and readily available ML libraries have enabled the application of ML to open software engineering challenges. Yet, the use of ML to enable decision-making during the software engineering lifecycle is not well understood as there are various ML models requiring parameter tuning. In this paper, we leverage ML techniques to develop an effective approach to classify software requirements. Specifically, we investigate the design and application of two types of neural network models, an artificial neural network (ANN) and a convolutional neural network (CNN), to classify non-functional requirements (NFRs) into the following five categories: maintainability, operability, performance, security and usability. We illustrate and experimentally evaluate this work through two widely used datasets consisting of nearly 1,000 NFRs. Our results indicate that our CNN model can effectively classify NFRs by achieving precision ranging between 82% and 94%, recall ranging between 76% and 97% with an F-score ranging between 82% and 92%.","","","10.1109/COMPSAC.2019.10275","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8754214","non-functional requirements;requirements engineering;machine learning","Software;Conferences","convolutional neural nets;formal specification;learning (artificial intelligence);software quality","CNN model;automatic multiclass nonfunctional software requirements classification;neural networks;machine learning;software engineering lifecycle;ML models;neural network models;artificial neural network;convolutional neural network;nonfunctional requirements;NFR","","","","24","","","","","IEEE","IEEE Conferences"
"A Systematic Approach of Dataset Definition for a Supervised Machine Learning Using NFR Framework","M. Marinho; D. Arruda; F. Wanderley; A. Lins","Centro de Cienc. e Tecnol., Univ. Catolica de Pernambuco, Recife, Brazil; Centro de Cienc. e Tecnol., Univ. Catolica de Pernambuco, Recife, Brazil; Centro de Cienc. e Tecnol., Univ. Catolica de Pernambuco, Recife, Brazil; Centro de Cienc. e Tecnol., Univ. Catolica de Pernambuco, Recife, Brazil","2018 11th International Conference on the Quality of Information and Communications Technology (QUATIC)","","2018","","","110","118","Non-functional requirements describe important constraints upon the software development and should therefore be considered and specified as early as possible during the system analysis. Effective elicitation of requirements is arguably among the most important of the resulting recommended RE practices. Recent research has shown that artificial intelligence techniques such as Machine Learning and Text Mining perform the automatic extraction and classification of quality attributes from text documents with relevant results. This paper aims to define a systematic process of dataset generation through NFR Framework catalogues improving the NFR's classification process using Machine Learning techniques. A well-known dataset (Promise) was used to evaluate the precision of our approach reaching interesting results. Regarding to security and performance we obtained a precision and recall ranging between ~85% and ~98%. And we achievement a F1 above ~79% when classified the security, performance and usability together.","","","10.1109/QUATIC.2018.00024","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8590177","non-fucntional requirements;NFR framework;artificial inteligence;machine learning;SIG","Machine learning;Systematics;Security;Requirements engineering;Usability","data mining;formal specification;formal verification;learning (artificial intelligence);pattern classification;systems analysis;text analysis","systematic approach;dataset definition;nonfunctional requirements;software development;system analysis;artificial intelligence techniques;automatic extraction;text documents;systematic process;dataset generation;NFR's classification process;text mining;supervised machine learning techniques","","","","44","","","","","IEEE","IEEE Conferences"
"Automated Validation of Requirement Reviews: A Machine Learning Approach","M. Singh","Dept. of Comput. Sci. & Eng., North Dakota State Univ., Fargo, ND, USA","2018 IEEE 26th International Requirements Engineering Conference (RE)","","2018","","","460","465","Software development is fault-prone especially during the fuzzy phases (requirements and design). Software inspections are commonly used in industry to detect and fix problems in requirements and design artifacts thereby mitigating the fault propagation to later phases where same faults are harder to find and fix. The output of an inspection process is natural language (NL) reviews that report the location and description of faults in software requirements specification document (SRS). The artifact author must manually read through the reviews and differentiate between true-faults and false-positives before fixing the faults. The time spent in making effective post-inspection decisions (number of true faults and deciding whether to re-inspect) could be spent in doing actual development work. The goal of this research is to automate the validation of inspection reviews, finding common patterns that describe high-quality requirements, identify fault prone requirements pre-inspection, and interrelated requirements to assist fixation of reported faults post-inspection. To accomplish these goals, this research employs various classification approaches, NL processing with semantic analysis and mining solutions from graph theory to requirement reviews and NL requirements. Initial results w.r.t. validation of inspection reviews have shown that our proposed approaches were able to successfully categorize useful and non-useful reviews.",";","","10.1109/RE.2018.00062","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8491169","requirement inspections;classification;semantic analysis;topic modeling;high quality requirements;interrelated requirements;part of speech tags","Inspection;Software;Semantics;Fault diagnosis;Analytical models;Data mining;Natural languages","data mining;formal specification;graph theory;inspection;learning (artificial intelligence);natural language processing;program diagnostics;software development management;software fault tolerance;software quality","requirement reviews;software development;fuzzy phases;software inspections;design artifacts;fault propagation;inspection process;software requirements specification document;actual development work;inspection reviews;high-quality requirements;fault prone requirements pre-inspection;interrelated requirements;reported faults post-inspection;NL processing;NL requirements;post-inspection decisions","","","","23","","","","","IEEE","IEEE Conferences"
"SReYantra: Automated Software Requirement Inter-Dependencies Elicitation, Analysis and Learning","G. Deshpande","University of Calgary","2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)","","2019","","","186","187","Requirements elicitation is a cognitively difficult task. Rich semantics in natural language based requirements impose challenges in elicitation, analysis and maintenance of requirement inter-dependencies. The challenges intensify further when dependency types and strengths are considered. Ignoring inter-dependencies can adversely impact the design, development and testing of software products. This PhD research proposal addresses three main challenges. First, Natural Language Processing (NLP) is studied to automatically extract dependencies from textual documents. Further verb classifiers are utilized to automate elicitation and analysis of different types of dependencies (e.g: requires, coupling etc). Second, representation and maintenance of changing requirement dependencies from designing graph theoretic algorithms will be explored. Third, the process of providing recommendations of dependencies will be studied. The results are aimed at assisting project managers to evaluate the impact of inter-dependencies and make effective decisions in software development life cycle.",";","","10.1109/ICSE-Companion.2019.00076","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8802756","Requirements Engineering, Requirements Interdependency Management, NLP, Machine Learning","","formal specification;graph theory;learning (artificial intelligence);natural language processing;software engineering","automated software requirement inter-dependencies elicitation;requirements elicitation;natural language based requirements;maintenance;software products;PhD research proposal;requirement dependencies;software development life cycle;natural language processing;SReYantra;NLP;dependencies extraction;graph theoretic algorithms","","","","9","","","","","IEEE","IEEE Conferences"
"Weka meets TraceLab: Toward convenient classification: Machine learning for requirements engineering problems: A position paper","J. H. Hayes; W. Li; M. Rahimi","Computer Science Department University of Kentucky Lexington, Kentucky, USA; Computer Science Department University of Kentucky Lexington, Kentucky, USA; School of Computing DePaul University Chicago, Illinois, USA","2014 IEEE 1st International Workshop on Artificial Intelligence for Requirements Engineering (AIRE)","","2014","","","9","12","Requirements engineering encompasses many difficult, overarching problems inherent to its subareas of process, elicitation, specification, analysis, and validation. Requirements engineering researchers seek innovative, effective means of addressing these problems. One powerful tool that can be added to the researcher toolkit is that of machine learning. Some researchers have been experimenting with their own implementations of machine learning algorithms or with those available as part of the Weka machine learning software suite. There are some shortcomings to using “one off” solutions. It is the position of the authors that many problems exist in requirements engineering that can be supported by Weka's machine learning algorithms, specifically by classification trees. Further, the authors posit that adoption will be boosted if machine learning is easy to use and is integrated into requirements research tools, such as TraceLab. Toward that end, an initial concept validation of a component in TraceLab is presented that applies the Weka classification trees. The component is demonstrated on two different requirements engineering problems. Finally, insights gained on using the TraceLab Weka component on these two problems are offered.","","","10.1109/AIRE.2014.6894850","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=6894850","Artificial intelligence;machine learning;requirements engineering;classification;decision trees;TraceLab;Weka","Classification tree analysis;Classification algorithms;Machine learning algorithms;Educational institutions;Software;Supervised learning","decision trees;formal specification;learning (artificial intelligence);pattern classification","TraceLab Weka component;Weka classification trees;requirements research tools;one off solutions;requirements engineering problems;Weka machine learning software suite","","4","","12","","","","","IEEE","IEEE Conferences"
"Software Feature Request Detection in Issue Tracking Systems","T. Merten; M. Falis; P. Hübner; T. Quirchmayr; S. Bürsner; B. Paech","NA; NA; NA; NA; NA; NA","2016 IEEE 24th International Requirements Engineering Conference (RE)","","2016","","","166","175","Communication about requirements is often handled in issue tracking systems, especially in a distributed setting. As issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. This paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. It compares traditional linguistic machine learning features, such as ""bag of words"", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. Our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. We show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. Finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. In addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.","","","10.1109/RE.2016.8","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7765522","Software Feature Request Detection;Mining Software Repositories;Machine Learning;Natural Language Processing","Software;Computer bugs;Natural languages;Feature extraction;Machine learning algorithms;Prediction algorithms;Training data","learning (artificial intelligence);natural language processing;program debugging;systems analysis","software feature request detection;issue tracking systems;requirements engineering;bug reports;programming tasks;natural language processing;machine learning;natural language data;bag of words;subject-action-object;meta-data;data fields","","13","","28","","","","","IEEE","IEEE Conferences"
"RE Data Challenge: Requirements Identification with Word2Vec and TensorFlow","A. Dekhtyar; V. Fong","NA; NA","2017 IEEE 25th International Requirements Engineering Conference (RE)","","2017","","","484","489","Since their introduction over a year ago, Google's TensorFlow package for learning with multilayer neural networks and their Word2Vec representation of words have both gained a high degree of notoriety. This paper considers the application of TensorFlow-guided learning and Word2Vec-based representations to the problems of classification in requirements documents. In this paper, we compare three categories of machine learning techniques for requirements identification for the SecReq and NFR datasets. The first category is the baseline method used in prior work: Naïve Bayes over word count and TF-IDF representations of requirements. The remaining two categories of techniques are the training of TensorFlow's convolutional neural networks on random and pre-trained Word2Vec embeddings of the words found in the requirements. This paper reports on the experiments we conducted and the accuracy results we achieved.","","","10.1109/RE.2017.26","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=8049170","machine learning;convolutional neural networks;requirements identification;TensorFlow;Word2Vec","Convolution;Google;Vocabulary;Feature extraction;Neural networks;Training","Bayes methods;formal specification;learning (artificial intelligence);natural language processing;neural nets;pattern classification;systems analysis;text analysis","multilayer neural networks;Word2Vec representation;requirements documents;requirements identification;word count;Word2Vec embeddings;Google TensorFlow package;TensorFlow convolutional neural networks;TensorFlow-guided learning;machine learning techniques;SecReq dataset;NFR dataset;naive Bayes;TF-IDF representation","","3","","13","","","","","IEEE","IEEE Conferences"
"Measuring Requirement Quality to Predict Testability","J. H. Hayes; W. Li; T. Yu; X. Han; M. Hays; C. Woodson","Department of Computer Science University of Kentucky USA; Department of Computer Science University of Kentucky USA; Department of Computer Science University of Kentucky USA; Department of Computer Science University of Kentucky USA; Department of Computer Science University of Kentucky USA; Department of Computer Science University of Kentucky USA","2015 IEEE Second International Workshop on Artificial Intelligence for Requirements Engineering (AIRE)","","2015","","","1","8","Software bugs contribute to the cost of ownership for consumers in a software-driven society and can potentially lead to devastating failures. Software testing, including functional testing and structural testing, remains a common method for uncovering faults and assessing dependability of software systems. To enhance testing effectiveness, the developed artifacts (requirements, code) must be designed to be testable. Prior work has developed many approaches to address the testability of code when applied to structural testing, but to date no work has considered approaches for assessing and predicting testability of requirements to aid functional testing. In this work, we address requirement testability from the perspective of requirement understandability and quality using a machine learning and statistical analysis approach. We first use requirement measures to empirically investigate the relevant relationship between each measure and requirement testability. We then assess relevant requirement measures for predicting requirement testability. We examined two datasets, each consisting of requirement and code artifacts. We found that several measures assist in delineating between the testable and non-testable requirements, and found anecdotal evidence that a learned model of testability can be used to guide evaluation of requirements for other (non-trained) systems.","","","10.1109/AIRE.2015.7337622","","https://ieeexplore.ieee.org.ezproxy.cdigital.uv.mx:8443/stamp/stamp.jsp?arnumber=7337622","requirement testability;code testability;machine learning;supervised classification learning;statistical analysis;correlation analysis;subjective assessment;human analyst","Testing;Correlation;Software;Indexes;Browsers;Logistics;Statistical analysis","formal verification;learning (artificial intelligence);program debugging;program testing;software quality;statistical analysis","requirement quality measurement;testability prediction;software bugs;ownership cost;software-driven society;software testing;functional testing;structural testing;software system fault;software system dependability assessment;code testability;requirement testability;requirement understandability;machine learning;statistical analysis approach","","2","","23","","","","","IEEE","IEEE Conferences"
